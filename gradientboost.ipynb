{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ecd30f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: editdistance in c:\\users\\benar\\anaconda3\\envs\\erdos_ds_environment\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: unidecode in c:\\users\\benar\\anaconda3\\envs\\erdos_ds_environment\\lib\\site-packages (1.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Run pip install to get libraries:\n",
    "%pip install editdistance unidecode\n",
    "\n",
    "# Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import roc_auc_score, log_loss, accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "import editdistance\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac81bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "PARQUET_TRAIN = \"data/processed/train_slam_with_features.parquet\"\n",
    "PARQUET_DEV   = \"data/processed/dev_slam_with_features.parquet\"\n",
    "PARQUET_TEST  = \"data/processed/test_slam_with_features.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf46fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "train = pd.read_parquet(PARQUET_TRAIN)\n",
    "dev   = pd.read_parquet(PARQUET_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42969504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word Comparisons File\n",
    "trans = pd.read_csv(\"data/processed/language_translation_table.csv\")\n",
    "\n",
    "# maps from translation table\n",
    "en_map = dict(zip(trans[\"uni_lemma\"], trans[\"English\"].astype(str)))\n",
    "fr_map = dict(zip(trans[\"uni_lemma\"], trans[\"French\"].astype(str)))\n",
    "es_map = dict(zip(trans[\"uni_lemma\"], trans[\"Spanish\"].astype(str)))\n",
    "\n",
    "def norm(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    s = unidecode(str(s)).lower().strip()\n",
    "    parts = s.split()\n",
    "    if len(parts) == 2 and parts[0] in {\"to\",\"i\",\"we\",\"you\",\"they\",\"he\",\"she\",\"the\",\"i'll\"}:\n",
    "        s = parts[1]\n",
    "    elif len(parts) > 2 and len(parts) > 1 and parts[1] == \"will\":\n",
    "        s = \" \".join(parts[2:])\n",
    "    return s\n",
    " \n",
    "def add_edit_distance_features(df):\n",
    "    key = df[\"uni_lemma\"]\n",
    "\n",
    "    # english and target by l2\n",
    "    eng = key.map(en_map)\n",
    "    tgt = np.where(df[\"l2\"].eq(\"fr\"), key.map(fr_map),\n",
    "        np.where(df[\"l2\"].eq(\"es\"), key.map(es_map), np.nan))\n",
    "\n",
    "    eng_n = pd.Series(eng).map(norm)\n",
    "    tgt_n = pd.Series(tgt).map(norm)\n",
    "\n",
    "    mask = eng_n.notna() & tgt_n.notna()\n",
    "    dist = np.full(len(df), np.nan, dtype=float)\n",
    "    dist[mask.values] = [editdistance.eval(a, b) for a, b in zip(eng_n[mask], tgt_n[mask])]\n",
    "    maxlen = np.maximum(eng_n.str.len(), tgt_n.str.len()).replace(0, 1)\n",
    "    frac = dist / maxlen.to_numpy()\n",
    "\n",
    "    df[\"edit_l2\"] = dist\n",
    "    df[\"edit_l2_frac\"] = frac\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f1ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_edit_distance_features(train)\n",
    "dev = add_edit_distance_features(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd34967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_pos</th>\n",
       "      <th>token_morph</th>\n",
       "      <th>token_dep_label</th>\n",
       "      <th>token_edges</th>\n",
       "      <th>token_wrong</th>\n",
       "      <th>block_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>user</th>\n",
       "      <th>...</th>\n",
       "      <th>format</th>\n",
       "      <th>time</th>\n",
       "      <th>l2</th>\n",
       "      <th>l1</th>\n",
       "      <th>uni_lemma</th>\n",
       "      <th>category</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>median_aoa</th>\n",
       "      <th>edit_l2</th>\n",
       "      <th>edit_l2_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8XTyQUAl0101</td>\n",
       "      <td>Le</td>\n",
       "      <td>DET</td>\n",
       "      <td>Definite=Def|Gender=Masc|Number=Sing|fPOS=DET++</td>\n",
       "      <td>det</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The boy</td>\n",
       "      <td>YjS/mQOx</td>\n",
       "      <td>...</td>\n",
       "      <td>reverse_translate</td>\n",
       "      <td>14.0</td>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8XTyQUAl0102</td>\n",
       "      <td>garçon</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Gender=Masc|Number=Sing|fPOS=NOUN++</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The boy</td>\n",
       "      <td>YjS/mQOx</td>\n",
       "      <td>...</td>\n",
       "      <td>reverse_translate</td>\n",
       "      <td>14.0</td>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "      <td>boy</td>\n",
       "      <td>people</td>\n",
       "      <td>0.226911</td>\n",
       "      <td>24.350613</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8XTyQUAl0201</td>\n",
       "      <td>Je</td>\n",
       "      <td>PRON</td>\n",
       "      <td>Number=Sing|Person=1|PronType=Prs|fPOS=PRON++</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I am a woman.</td>\n",
       "      <td>YjS/mQOx</td>\n",
       "      <td>...</td>\n",
       "      <td>reverse_translate</td>\n",
       "      <td>14.0</td>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8XTyQUAl0202</td>\n",
       "      <td>suis</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbF...</td>\n",
       "      <td>cop</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I am a woman.</td>\n",
       "      <td>YjS/mQOx</td>\n",
       "      <td>...</td>\n",
       "      <td>reverse_translate</td>\n",
       "      <td>14.0</td>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "      <td>am</td>\n",
       "      <td>helping_verbs</td>\n",
       "      <td>0.294798</td>\n",
       "      <td>29.568209</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8XTyQUAl0203</td>\n",
       "      <td>une</td>\n",
       "      <td>DET</td>\n",
       "      <td>Definite=Ind|Gender=Fem|Number=Sing|PronType=D...</td>\n",
       "      <td>det</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I am a woman.</td>\n",
       "      <td>YjS/mQOx</td>\n",
       "      <td>...</td>\n",
       "      <td>reverse_translate</td>\n",
       "      <td>14.0</td>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "      <td>a</td>\n",
       "      <td>quantifiers</td>\n",
       "      <td>0.239488</td>\n",
       "      <td>27.849093</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       token_id   token token_pos  \\\n",
       "0  8XTyQUAl0101      Le       DET   \n",
       "1  8XTyQUAl0102  garçon      NOUN   \n",
       "2  8XTyQUAl0201      Je      PRON   \n",
       "3  8XTyQUAl0202    suis      VERB   \n",
       "4  8XTyQUAl0203     une       DET   \n",
       "\n",
       "                                         token_morph token_dep_label  \\\n",
       "0    Definite=Def|Gender=Masc|Number=Sing|fPOS=DET++             det   \n",
       "1                Gender=Masc|Number=Sing|fPOS=NOUN++            ROOT   \n",
       "2      Number=Sing|Person=1|PronType=Prs|fPOS=PRON++           nsubj   \n",
       "3  Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbF...             cop   \n",
       "4  Definite=Ind|Gender=Fem|Number=Sing|PronType=D...             det   \n",
       "\n",
       "  token_edges  token_wrong  block_id         prompt      user  ...  \\\n",
       "0           2            0         1        The boy  YjS/mQOx  ...   \n",
       "1           0            0         1        The boy  YjS/mQOx  ...   \n",
       "2           4            0         2  I am a woman.  YjS/mQOx  ...   \n",
       "3           4            0         2  I am a woman.  YjS/mQOx  ...   \n",
       "4           4            0         2  I am a woman.  YjS/mQOx  ...   \n",
       "\n",
       "              format  time  l2  l1 uni_lemma       category growth_rate  \\\n",
       "0  reverse_translate  14.0  fr  en      None           None         NaN   \n",
       "1  reverse_translate  14.0  fr  en       boy         people    0.226911   \n",
       "2  reverse_translate  14.0  fr  en      None           None         NaN   \n",
       "3  reverse_translate  14.0  fr  en        am  helping_verbs    0.294798   \n",
       "4  reverse_translate  14.0  fr  en         a    quantifiers    0.239488   \n",
       "\n",
       "  median_aoa edit_l2 edit_l2_frac  \n",
       "0        NaN     NaN          NaN  \n",
       "1  24.350613     5.0     0.833333  \n",
       "2        NaN     NaN          NaN  \n",
       "3  29.568209     4.0     1.000000  \n",
       "4  27.849093     5.0     0.833333  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f9522f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['token_id', 'token', 'token_pos', 'token_morph', 'token_dep_label',\n",
       "       'token_edges', 'token_wrong', 'block_id', 'prompt', 'user',\n",
       "       'countries', 'days', 'client', 'session', 'format', 'time', 'l2',\n",
       "       'l1', 'uni_lemma', 'category', 'growth_rate', 'median_aoa',\n",
       "       'edit_l2', 'edit_l2_frac'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d57aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_id            object\n",
      "token               object\n",
      "token_pos           object\n",
      "token_morph         object\n",
      "token_dep_label     object\n",
      "token_edges         object\n",
      "token_wrong          int64\n",
      "block_id             int64\n",
      "prompt              object\n",
      "user                object\n",
      "countries           object\n",
      "days               float64\n",
      "client              object\n",
      "session             object\n",
      "format              object\n",
      "time               float64\n",
      "l2                  object\n",
      "l1                  object\n",
      "uni_lemma           object\n",
      "category            object\n",
      "growth_rate        float64\n",
      "median_aoa         float64\n",
      "edit_l2            float64\n",
      "edit_l2_frac       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c72520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select predictors and dependent variable\n",
    "predictors = ['median_aoa', 'edit_l2_frac', 'user', 'days', 'growth_rate']\n",
    "target = 'token_wrong'\n",
    "\n",
    "\n",
    "# Encode categoricals\n",
    "train['user'] = train['user'].astype('category')\n",
    "dev['user'] = dev['user'].astype('category')\n",
    "\n",
    "categorical_features = ['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa3f82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LightGBM dataset\n",
    "lgb_train = lgb.Dataset(train[predictors], label=train[target], categorical_feature=categorical_features)\n",
    "lgb_val = lgb.Dataset(dev[predictors],     label=dev[target],   categorical_feature=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "617214d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 512,\n",
    "    'min_data_in_leaf': 100,\n",
    "    \"cat_smooth\": 200,\n",
    "    'feature_fraction': 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7109483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 758625, number of negative: 4764534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.167258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6887\n",
      "[LightGBM] [Info] Number of data points in the train set: 5523159, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137353 -> initscore=-1.837447\n",
      "[LightGBM] [Info] Start training from score -1.837447\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's auc: 0.690381\tval's auc: 0.651017\n",
      "[100]\ttrain's auc: 0.700399\tval's auc: 0.653975\n",
      "[150]\ttrain's auc: 0.706569\tval's auc: 0.65466\n",
      "[200]\ttrain's auc: 0.710284\tval's auc: 0.654699\n",
      "[250]\ttrain's auc: 0.712855\tval's auc: 0.654634\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttrain's auc: 0.711558\tval's auc: 0.654739\n",
      "Trees trained: 224\n",
      "Current iteration: 224\n",
      "Best iteration: 224\n",
      "Eval results: defaultdict(<class 'collections.OrderedDict'>, {'train': OrderedDict({'auc': np.float64(0.7115580614717314)}), 'val': OrderedDict({'auc': np.float64(0.6547387784704626)})})\n",
      "===== Evaluation Metrics =====\n",
      "AUC: 0.6547\n",
      "Log Loss:   0.4082\n",
      "Accuracy:   0.8468\n",
      "Precision:  0.5371\n",
      "Recall:     0.0189\n",
      "F1 Score:   0.0365\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_val],\n",
    "    valid_names=['train', 'val'],\n",
    "    num_boost_round=500,\n",
    "    callbacks=[\n",
    "        lgb.log_evaluation(period=50),           # print every 50 iters\n",
    "        lgb.early_stopping(stopping_rounds=50),  # set best_iteration\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Check parameters settings\n",
    "print(\"Trees trained:\", model.num_trees()) \n",
    "print(\"Current iteration:\", model.current_iteration())\n",
    "print(\"Best iteration:\", model.best_iteration)\n",
    "print(\"Eval results:\", model.best_score)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(dev[predictors], num_iteration=model.best_iteration)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "auc = metrics.roc_auc_score(dev[target], y_pred)\n",
    "logloss = metrics.log_loss(dev[target], y_pred)\n",
    "accuracy = metrics.accuracy_score(dev[target], y_pred_label)\n",
    "precision = metrics.precision_score(dev[target], y_pred_label)\n",
    "recall = metrics.recall_score(dev[target], y_pred_label)\n",
    "f1 = metrics.f1_score(dev[target], y_pred_label)\n",
    "conf_matrix = metrics.confusion_matrix(dev[target], y_pred_label)\n",
    "\n",
    "print(\"===== Evaluation Metrics =====\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Log Loss:   {logloss:.4f}\")\n",
    "print(f\"Accuracy:   {accuracy:.4f}\")\n",
    "print(f\"Precision:  {precision:.4f}\")\n",
    "print(f\"Recall:     {recall:.4f}\")\n",
    "print(f\"F1 Score:   {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
