{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8edb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load data taken from:\n",
    "# https://github.com/nathgoh/CS230-Duolingo/blob/main/LSTM%20notebooks/get_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bc20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict, namedtuple\n",
    "from io import open\n",
    "import math\n",
    "import os\n",
    "from random import shuffle, uniform\n",
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1940b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, key = None):\n",
    "    \"\"\"\n",
    "    This method loads and returns the data in filename. If the data is labelled training data, it returns labels too.\n",
    "\n",
    "    Parameters:\n",
    "        filename: the location of the training or test data you want to load.\n",
    "        key: the labels for the test data should we be loading in a test data\n",
    "\n",
    "    Returns:\n",
    "        data: a list of InstanceData objects from that data type and track, includes the labels\n",
    "    \"\"\"\n",
    "\n",
    "    # 'data' stores a list of 'InstanceData's as values.\n",
    "    data = []\n",
    "\n",
    "    # If this is training data, then 'labels' is a dict that contains instance_ids as keys and labels as values.\n",
    "    training = False\n",
    "    if filename.find('train') != -1:\n",
    "        training = True\n",
    "\n",
    "    if training:\n",
    "        labels = dict()\n",
    "\n",
    "    test_key = [] \n",
    "    if key:    \n",
    "        print('Loading test labels...')\n",
    "        with open(key, 'rt', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                temp = dict()\n",
    "                temp['instance_id'], temp['label'] = line.split()\n",
    "                temp['label'] = float(temp['label'])\n",
    "                test_key.append(temp['label'])\n",
    "\n",
    "    num_exercises = 0\n",
    "    print('Loading instances...')\n",
    "    instance_properties = dict()\n",
    "\n",
    "    with open(filename, 'rt') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "            if len(line) == 0:\n",
    "                num_exercises += 1\n",
    "                if num_exercises % 100000 == 0:\n",
    "                    print('Loaded ' + str(len(data)) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
    "                instance_properties = dict()\n",
    "\n",
    "            # If the line starts with #, then we're beginning a new exercise\n",
    "            elif line[0] == '#':\n",
    "                if 'prompt' in line:\n",
    "                    instance_properties['prompt'] = line.split(':')[1]\n",
    "                else:\n",
    "                    list_of_exercise_parameters = line[2:].split()\n",
    "                    for exercise_parameter in list_of_exercise_parameters:\n",
    "                        [key, value] = exercise_parameter.split(':')\n",
    "                        if key == 'countries':\n",
    "                            value = value.split('|')\n",
    "                        elif key == 'days':\n",
    "                            value = float(value)\n",
    "                        elif key == 'time':\n",
    "                            if value == 'null':\n",
    "                                value = None\n",
    "                            else:\n",
    "                                assert '.' not in value\n",
    "                                value = int(value)\n",
    "                        instance_properties[key] = value\n",
    "\n",
    "            # Otherwise we're parsing a new Instance for the current exercise\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if training:\n",
    "                    assert len(line) == 7\n",
    "                else:\n",
    "                    assert len(line) == 6\n",
    "                assert len(line[0]) == 12\n",
    "\n",
    "                instance_properties['instance_id'] = line[0]\n",
    "                instance_properties['token'] = line[1]\n",
    "                instance_properties['part_of_speech'] = line[2]\n",
    "                instance_properties['dependency_label'] = line[4]\n",
    "                instance_properties['dependency_edge_head'] = int(line[5])\n",
    "                if training:\n",
    "                    label = float(line[6])\n",
    "                    labels[instance_properties['instance_id']] = label\n",
    "                    instance_properties['label'] = float(line[6])\n",
    "                if key and test_key != []:\n",
    "                    instance_properties['label'] = test_key.pop(0)\n",
    "                data.append(InstanceData(instance_properties=instance_properties))\n",
    "\n",
    "        print('Done loading ' + str(len(data)) + ' instances across ' + str(num_exercises) +\n",
    "              ' exercises.\\n')\n",
    "\n",
    "    return data\n",
    "\n",
    "class InstanceData(object):\n",
    "    \"\"\"\n",
    "    A bare-bones class to store the included properties of each instance. This is meant to act as easy access to the\n",
    "    data, and provides a launching point for deriving your own features from the data.\n",
    "    \"\"\"\n",
    "    def __init__(self, instance_properties):\n",
    "\n",
    "        # Parameters specific to this instance\n",
    "        self.instance_id = instance_properties['instance_id']\n",
    "        self.token = instance_properties['token']\n",
    "        self.part_of_speech = instance_properties['part_of_speech']\n",
    "        # self.morphological_features = instance_properties['morphological_features']\n",
    "        self.dependency_label = instance_properties['dependency_label']\n",
    "        self.dependency_edge_head = instance_properties['dependency_edge_head']\n",
    "\n",
    "        # Derived parameters specific to this instance\n",
    "        self.exercise_index = int(self.instance_id[8:10])\n",
    "        self.token_index = int(self.instance_id[10:12])\n",
    "\n",
    "        # Derived parameters specific to this exercise\n",
    "        self.exercise_id = self.instance_id[:10]\n",
    "\n",
    "        # Parameters shared across the whole session\n",
    "        self.user = instance_properties['user']\n",
    "        self.countries = instance_properties['countries']\n",
    "        self.days = instance_properties['days']\n",
    "        self.client = instance_properties['client']\n",
    "        self.session = instance_properties['session']\n",
    "        self.format = instance_properties['format']\n",
    "        self.time = instance_properties['time']\n",
    "        self.prompt = instance_properties.get('prompt', None)\n",
    "\n",
    "        # Label\n",
    "        self.label = instance_properties['label']\n",
    "\n",
    "        # Derived parameters shared across the whole session\n",
    "        self.session_id = self.instance_id[:8]\n",
    "\n",
    "    # Get the 0,1 label\n",
    "    def get_label(self):\n",
    "        return self.label\n",
    "\n",
    "    # Exercise-level features \n",
    "    def get_format(self):\n",
    "        return self.format\n",
    "    def get_user(self):\n",
    "        return self.user\n",
    "    def get_countries(self):\n",
    "        return self.countries\n",
    "    def get_session(self):\n",
    "        return self.session\n",
    "\n",
    "    # Added\n",
    "    def get_prompt(self):\n",
    "        return self.prompt\n",
    "    \n",
    "    # Word-level features\n",
    "    def get_token(self):\n",
    "        return self.token.lower()\n",
    "    def get_part_of_speech(self):\n",
    "        return self.part_of_speech\n",
    "    def get_dependency_label(self):\n",
    "        return self.dependency_label\n",
    "\n",
    "    def to_features(self):\n",
    "        \"\"\"\n",
    "        Prepares those features that we wish to use in the LogisticRegression example in this file. We introduce a bias,\n",
    "        and take a few included features to use. Note that this dict restructures the corresponding features of the\n",
    "        input dictionary, 'instance_properties'.\n",
    "\n",
    "        Returns:\n",
    "            to_return: a representation of the features we'll use for logistic regression in a dict. A key/feature is a\n",
    "                key/value pair of the original 'instance_properties' dict, and we encode this feature as 1.0 for 'hot'.\n",
    "        \"\"\"\n",
    "        to_return = dict()\n",
    "\n",
    "        to_return['bias'] = 1.0\n",
    "        to_return['user:' + self.user] = 1.0\n",
    "        to_return['format:' + self.format] = 1.0\n",
    "        to_return['token:' + self.token.lower()] = 1.0\n",
    "\n",
    "        to_return['part_of_speech:' + self.part_of_speech] = 1.0\n",
    "        # for morphological_feature in self.morphological_features:\n",
    "        #     to_return['morphological_feature:' + morphological_feature] = 1.0\n",
    "        to_return['dependency_label:' + self.dependency_label] = 1.0\n",
    "\n",
    "        return to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc90af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "def get_raw_dataset(train, test, key):\n",
    "    print(\"Getting training data...\")\n",
    "    training_data = load_data(train)\n",
    "\n",
    "    print(\"Getting test data...\")\n",
    "    test_data = load_data(test, key)\n",
    "\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78108944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting training data...\n",
      "Loading instances...\n",
      "Loaded 317049 instances across 100000 exercises...\n",
      "Loaded 635368 instances across 200000 exercises...\n",
      "Loaded 951536 instances across 300000 exercises...\n",
      "Loaded 1271940 instances across 400000 exercises...\n",
      "Loaded 1591344 instances across 500000 exercises...\n",
      "Loaded 1911212 instances across 600000 exercises...\n",
      "Loaded 2227444 instances across 700000 exercises...\n",
      "Loaded 2546704 instances across 800000 exercises...\n",
      "Done loading 2622957 instances across 824012 exercises.\n",
      "\n",
      "Getting test data...\n",
      "Loading test labels...\n",
      "Loading instances...\n",
      "Loaded 337728 instances across 100000 exercises...\n",
      "Done loading 386604 instances across 114586 exercises.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_raw_dataset(\"../00_data/raw/dataverse_files/data_en_es/en_es.slam.20190204.train\", \"../00_data/raw/dataverse_files/data_en_es/en_es.slam.20190204.test\", \"../00_data/raw/dataverse_files/data_en_es/en_es.slam.20190204.test.key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220761ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[0].get_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53a801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the dataset into a pandas dataframe that only contains the labels and features\n",
    "# we want to use in our model\n",
    "def build_formatted_dataset(data):\n",
    "    users, formats, countries, sessions, tokens, part_of_speeches, dependency_labels, labels, prompts = [], [], [] ,[], [], [], [], [], []\n",
    "    \n",
    "    for instance_data in data:\n",
    "        users.append(instance_data.get_user())\n",
    "        formats.append(instance_data.get_format())\n",
    "        countries.append(instance_data.get_countries())\n",
    "        sessions.append(instance_data.get_session())\n",
    "        tokens.append(instance_data.get_token())\n",
    "        part_of_speeches.append(instance_data.get_part_of_speech())\n",
    "        dependency_labels.append(instance_data.get_dependency_label())\n",
    "        labels.append(instance_data.get_label())\n",
    "        prompts.append(instance_data.get_prompt())\n",
    "\n",
    "    dataset = {'user':users, 'country':countries, 'format':formats, 'session':sessions, 'token':tokens, 'part_of_speech':part_of_speeches, 'dependency_label':dependency_labels, 'label':labels, 'prompt':prompts}\n",
    "    dataset = pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d636279",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_train_data = build_formatted_dataset(train_data)\n",
    "formatted_test_data = build_formatted_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7abbfdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>country</th>\n",
       "      <th>format</th>\n",
       "      <th>session</th>\n",
       "      <th>token</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>dependency_label</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XEinXf5+</td>\n",
       "      <td>[CO]</td>\n",
       "      <td>reverse_translate</td>\n",
       "      <td>lesson</td>\n",
       "      <td>i</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yo soy un niño.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XEinXf5+</td>\n",
       "      <td>[CO]</td>\n",
       "      <td>reverse_translate</td>\n",
       "      <td>lesson</td>\n",
       "      <td>am</td>\n",
       "      <td>VERB</td>\n",
       "      <td>cop</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yo soy un niño.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XEinXf5+</td>\n",
       "      <td>[CO]</td>\n",
       "      <td>reverse_translate</td>\n",
       "      <td>lesson</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yo soy un niño.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XEinXf5+</td>\n",
       "      <td>[CO]</td>\n",
       "      <td>reverse_translate</td>\n",
       "      <td>lesson</td>\n",
       "      <td>boy</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yo soy un niño.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XEinXf5+</td>\n",
       "      <td>[CO]</td>\n",
       "      <td>reverse_translate</td>\n",
       "      <td>lesson</td>\n",
       "      <td>i</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yo soy de México.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user country             format session token part_of_speech  \\\n",
       "0  XEinXf5+    [CO]  reverse_translate  lesson     i           PRON   \n",
       "1  XEinXf5+    [CO]  reverse_translate  lesson    am           VERB   \n",
       "2  XEinXf5+    [CO]  reverse_translate  lesson     a            DET   \n",
       "3  XEinXf5+    [CO]  reverse_translate  lesson   boy           NOUN   \n",
       "4  XEinXf5+    [CO]  reverse_translate  lesson     i           PRON   \n",
       "\n",
       "  dependency_label  label             prompt  \n",
       "0            nsubj    0.0    Yo soy un niño.  \n",
       "1              cop    0.0    Yo soy un niño.  \n",
       "2              det    0.0    Yo soy un niño.  \n",
       "3             ROOT    0.0    Yo soy un niño.  \n",
       "4            nsubj    0.0  Yo soy de México.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbc348cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_train_data.to_pickle(\"../00_data/clean/en_es_train_data.pkl\")\n",
    "formatted_test_data.to_pickle(\"../00_data/clean/en_es_test_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efbd2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working_df = formatted_train_data[['token', 'part_of_speech', 'prompt']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
