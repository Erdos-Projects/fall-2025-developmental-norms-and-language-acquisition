{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WG = pd.read_csv('~/Downloads/wordbank_data_WG_Produces_en.csv')\n",
    "df_WG.drop(columns=['downloaded'], inplace=True)\n",
    "display(df_WG.head())\n",
    "\n",
    "df_WS = pd.read_csv('~/Downloads/wordbank_data_WS_Produces_en.csv')\n",
    "df_WS.drop(columns=['downloaded'], inplace=True)\n",
    "display(df_WS.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ASSUMPTION ---\n",
    "# This script assumes you have df_WS (Words & Sentences data) loaded and ready.\n",
    "# The proportion columns are assumed to be named '28', '29', and '30' (as strings).\n",
    "\n",
    "def analyze_proportion_dip(df, age_cols=['28', '29', '30']):\n",
    "    \"\"\"\n",
    "    Performs T-tests to compare the mean proportion acquired between 28, 29, and 30 months.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not all(col in df.columns for col in age_cols):\n",
    "        print(f\"Error: Not all required columns ({age_cols}) found in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Convert the proportion columns to numeric (they may be strings after the earlier DataFrame joins)\n",
    "    df[age_cols] = df[age_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    df = df.dropna(subset=age_cols)\n",
    "\n",
    "    # 1. Calculate Mean Proportions\n",
    "    mean_28 = df[age_cols[0]].mean()\n",
    "    mean_29 = df[age_cols[1]].mean()\n",
    "    mean_30 = df[age_cols[2]].mean()\n",
    "\n",
    "    print(\"--- Summary of Mean Proportions ---\")\n",
    "    print(f\"Mean Proportion Acquired at {age_cols[0]} months (Peak?): {mean_28:.4f}\")\n",
    "    print(f\"Mean Proportion Acquired at {age_cols[1]} months (Dip?):   {mean_29:.4f}\")\n",
    "    print(f\"Mean Proportion Acquired at {age_cols[2]} months (Dip?):   {mean_30:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # 2. Perform Paired T-tests (since the same items are measured)\n",
    "    \n",
    "    # Check if 28m is statistically higher than 29m\n",
    "    t_28_vs_29, p_28_vs_29 = stats.ttest_rel(df[age_cols[0]], df[age_cols[1]], alternative='greater')\n",
    "    \n",
    "    # Check if 28m is statistically higher than 30m\n",
    "    t_28_vs_30, p_28_vs_30 = stats.ttest_rel(df[age_cols[0]], df[age_cols[2]], alternative='greater')\n",
    "    \n",
    "    print(\"--- Paired T-test Results (Testing if 28m is significantly GREATER than 29m/30m) ---\")\n",
    "    \n",
    "    print(f\"28m vs 29m: T-statistic={t_28_vs_29:.3f}, P-value={p_28_vs_29:.5f}\")\n",
    "    if p_28_vs_29 < 0.05:\n",
    "        print(f\"   -> Result: Statistically significant dip from 28 to 29 months (p < 0.05).\")\n",
    "    else:\n",
    "        print(f\"   -> Result: Dip is NOT statistically significant (p >= 0.05).\")\n",
    "        \n",
    "    print(f\"28m vs 30m: T-statistic={t_28_vs_30:.3f}, P-value={p_28_vs_30:.5f}\")\n",
    "    if p_28_vs_30 < 0.05:\n",
    "        print(f\"   -> Result: Statistically significant dip from 28 to 30 months (p < 0.05).\")\n",
    "    else:\n",
    "        print(f\"   -> Result: Dip is NOT statistically significant (p >= 0.05).\")\n",
    "\n",
    "# Example Usage (replace df_WS with your actual DataFrame name)\n",
    "# You may need to adjust the column names if you added suffixes earlier (e.g., '28_WS')\n",
    "# analyze_proportion_dip(df_WS, age_cols=['28', '29', '30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_proportion_dip(df_WS, age_cols=['28', '29', '30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ASSUMPTION ---\n",
    "# This script assumes df_WS and df_WG have been successfully loaded and are available.\n",
    "# We assume age columns are represented as strings ('8', '9', '10', etc.).\n",
    "\n",
    "# Define the columns that should NOT be treated as age/proportion data.\n",
    "METADATA_COLS = ['item_id', 'item_definition', 'category']\n",
    "\n",
    "def get_numeric_age_columns(df, metadata_cols):\n",
    "    \"\"\"\n",
    "    Identifies and numerically sorts columns that represent ages (by excluding metadata\n",
    "    and ensuring they can be converted to integers).\n",
    "    \"\"\"\n",
    "    # 1. Get all column names that are not in the metadata list\n",
    "    potential_age_cols = df.columns.difference(metadata_cols).tolist()\n",
    "    \n",
    "    # 2. Filter to only include columns that are string representations of numbers\n",
    "    numeric_age_cols = [col for col in potential_age_cols if str(col).isdigit()]\n",
    "    \n",
    "    # 3. CRITICAL: Sort these column names numerically (not alphabetically)\n",
    "    # The key=int ensures '10' comes after '9', not after '1'.\n",
    "    sorted_age_cols = sorted(numeric_age_cols, key=int)\n",
    "    \n",
    "    return sorted_age_cols\n",
    "\n",
    "def analyze_all_adjacent_age_differences(df, inventory_name, metadata_cols):\n",
    "    \"\"\"\n",
    "    Performs paired T-tests for every adjacent age group in the DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"       ANALYZING ADJACENT MONTHLY CHANGES FOR: {inventory_name}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    age_cols = get_numeric_age_columns(df, metadata_cols)\n",
    "    \n",
    "    if len(age_cols) < 2:\n",
    "        print(f\"Insufficient age data found in {inventory_name}.\")\n",
    "        return\n",
    "\n",
    "    # Ensure all required columns are numeric and drop rows with missing values \n",
    "    # for the age columns we will test.\n",
    "    df_clean = df.copy()\n",
    "    df_clean[age_cols] = df_clean[age_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    df_clean = df_clean.dropna(subset=age_cols)\n",
    "    \n",
    "    N = len(df_clean)\n",
    "    print(f\"Total items analyzed: {N}\\n\")\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # Iterate through all adjacent pairs\n",
    "    for i in range(len(age_cols) - 1):\n",
    "        age_A = age_cols[i]\n",
    "        age_B = age_cols[i+1]\n",
    "        \n",
    "        # Data for the comparison\n",
    "        data_A = df_clean[age_A]\n",
    "        data_B = df_clean[age_B]\n",
    "\n",
    "        # Paired T-test (measures the difference between two related samples, \n",
    "        # which is appropriate here since it's the same item measured at two ages)\n",
    "        # We use 'two-sided' test to detect any significant change (increase or decrease)\n",
    "        t_stat, p_value = stats.ttest_rel(data_A, data_B, nan_policy='omit')\n",
    "        \n",
    "        # Calculate the direction of change\n",
    "        mean_A = data_A.mean()\n",
    "        mean_B = data_B.mean()\n",
    "        \n",
    "        change_direction = 'Increase' if mean_B > mean_A else ('Decrease' if mean_B < mean_A else 'No Change')\n",
    "        \n",
    "        # Determine significance\n",
    "        is_significant = 'YES (P < 0.05)' if p_value < 0.05 else 'NO'\n",
    "        \n",
    "        results.append({\n",
    "            'Comparison': f'{age_A}m -> {age_B}m',\n",
    "            'Mean_A': f'{mean_A:.3f}',\n",
    "            'Mean_B': f'{mean_B:.3f}',\n",
    "            'Change': change_direction,\n",
    "            'T_Statistic': f'{t_stat:.3f}',\n",
    "            'P_Value': f'{p_value:.5f}',\n",
    "            'Significant': is_significant\n",
    "        })\n",
    "\n",
    "    # Display results as a DataFrame for clean formatting\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n*Significance is defined as P-value < 0.05 (two-sided paired T-test).\")\n",
    "\n",
    "# Analyze Words & Gestures (df_WG)\n",
    "df_WG_results = analyze_all_adjacent_age_differences(df_WG, \"Words & Gestures (WG)\", METADATA_COLS)\n",
    "df_WG_results['Inventory'] = 'WG'\n",
    "df_WG_results = df_WG_results[['Inventory'] + df_WG_results.columns[:-1].tolist()]  # Reorder columns\n",
    "display(df_WG_results)\n",
    "\n",
    "# Analyze Words & Sentences (df_WS)\n",
    "df_WS_results = analyze_all_adjacent_age_differences(df_WS, \"Words & Sentences (WS)\", METADATA_COLS)\n",
    "df_WS_results['Inventory'] = 'WS'\n",
    "df_WS_results = df_WS_results[['Inventory'] + df_WS_results.columns[:-1].tolist()]  # Reorder columns\n",
    "display(df_WS_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSUMPTION: df_WS_results and df_WG_results DataFrames are already generated\n",
    "# and contain the necessary columns (Comparison, Mean_A, Mean_B, P_Value).\n",
    "\n",
    "def plot_comparison_statistics(df_ws, df_wg):\n",
    "    \"\"\"\n",
    "    Combines WS (blue dots) and WG (orange squares) results and plots the monthly \n",
    "    change in mean proportion (Age B - Age A) against the age transition.\n",
    "    Significant decreases (P < 0.05) are highlighted with red stars.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. CRITICAL FIX: Ensure 'Inventory' column exists on the results DataFrames\n",
    "    # This block handles cases where the analysis function output didn't include the column,\n",
    "    # or relies on the user's manual addition (like 'WS' and 'WG').\n",
    "    if 'Inventory' not in df_ws.columns:\n",
    "        df_ws['Inventory'] = 'Words & Sentences (WS)'\n",
    "    if 'Inventory' not in df_wg.columns:\n",
    "        df_wg['Inventory'] = 'Words & Gestures (WG)'\n",
    "        \n",
    "    # 2. Prepare dataframes for concatenation\n",
    "    # Ensure mean columns (stored as strings with f-formatting) are converted back to numeric\n",
    "    # for calculation, and calculate the Mean_Change column.\n",
    "    for df in [df_ws, df_wg]:\n",
    "        df['Mean_A'] = pd.to_numeric(df['Mean_A'], errors='coerce')\n",
    "        df['Mean_B'] = pd.to_numeric(df['Mean_B'], errors='coerce')\n",
    "        df['P_Value'] = pd.to_numeric(df['P_Value'], errors='coerce')\n",
    "        df['Mean_Change'] = df['Mean_B'] - df['Mean_A']\n",
    "    \n",
    "    # 3. Combine dataframes\n",
    "    df_combined = pd.concat([df_ws, df_wg], ignore_index=True)\n",
    "\n",
    "    # --- UPDATED LOGIC FOR X-AXIS ORDERING AND PLOTTING ---\n",
    "    # 3a. Extract the starting age (e.g., 8 from '8m -> 9m') for numerical sorting\n",
    "    df_combined['Start_Age_Int'] = df_combined['Comparison'].apply(\n",
    "        lambda x: int(x.split('m')[0])\n",
    "    )\n",
    "\n",
    "    # 3b. Sort the unique comparison labels chronologically\n",
    "    sorted_comparisons_df = df_combined[['Comparison', 'Start_Age_Int']].drop_duplicates().sort_values(by='Start_Age_Int')\n",
    "    ordered_comparisons = sorted_comparisons_df['Comparison'].tolist()\n",
    "    \n",
    "    # 3c. Create a mapping from Comparison string to its numerical index (0, 1, 2, ...)\n",
    "    comparison_to_index = {comp: i for i, comp in enumerate(ordered_comparisons)}\n",
    "    \n",
    "    # 3d. Apply the mapping to create the explicit X-coordinate column\n",
    "    df_combined['X_Position'] = df_combined['Comparison'].map(comparison_to_index)\n",
    "    \n",
    "    # 4. Setup plot\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # 5. Scatterplot logic (now using 'X_Position' for x-coordinates)\n",
    "    \n",
    "    # WS Data (Blue circles)\n",
    "    df_ws_plot = df_combined[df_combined['Inventory'].astype(str).str.contains('WS')]\n",
    "    plt.scatter(\n",
    "        df_ws_plot['X_Position'], # Use the explicit numerical index\n",
    "        df_ws_plot['Mean_Change'], \n",
    "        color='blue', \n",
    "        label='Words & Sentences (WS)', \n",
    "        s=100, # size of dots\n",
    "        alpha=0.7,\n",
    "        marker='o'\n",
    "    )\n",
    "    \n",
    "    # WG Data (Orange squares)\n",
    "    df_wg_plot = df_combined[df_combined['Inventory'].astype(str).str.contains('WG')]\n",
    "    plt.scatter(\n",
    "        df_wg_plot['X_Position'], # Use the explicit numerical index\n",
    "        df_wg_plot['Mean_Change'], \n",
    "        color='orange', \n",
    "        label='Words & Gestures (WG)', \n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        marker='s' \n",
    "    )\n",
    "    \n",
    "    # 6. Highlight significant decreases (Red stars)\n",
    "    sig_decreases = df_combined[\n",
    "        (df_combined['P_Value'] < 0.05) & \n",
    "        (df_combined['Mean_Change'] < 0)\n",
    "    ]\n",
    "    if not sig_decreases.empty:\n",
    "        plt.scatter(\n",
    "            sig_decreases['X_Position'], # Use the explicit numerical index\n",
    "            sig_decreases['Mean_Change'],\n",
    "            color='red',\n",
    "            marker='*',\n",
    "            s=250, # large star marker\n",
    "            label='Statistically Significant Decrease (P < 0.05)',\n",
    "            zorder=10 # Ensure stars are on top\n",
    "        )\n",
    "\n",
    "    # 7. Add reference lines and labels\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=1) \n",
    "    \n",
    "    plt.title('Monthly Change in Mean Vocabulary Proportion by Inventory', fontsize=16)\n",
    "    plt.xlabel('Adjacent Age Comparison (Months)', fontsize=12)\n",
    "    plt.ylabel('Change in Mean Proportion (Age B - Age A)', fontsize=12)\n",
    "    plt.legend(title='Inventory', loc='best')\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    \n",
    "    # Set the x-ticks explicitly using the index (0, 1, 2...) and the sorted labels\n",
    "    plt.gca().set_xticks(range(len(ordered_comparisons)))\n",
    "    plt.gca().set_xticklabels(ordered_comparisons)\n",
    "    \n",
    "    # Rotate x-axis labels for readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "\n",
    "# --- EXECUTION ---\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"       PLOTTING MONTHLY CHANGE IN MEAN PROPORTION\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "plot_comparison_statistics(df_WS_results, df_WG_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ASSUMPTION: df_WS_results and df_WG_results DataFrames are already generated\n",
    "# and contain the necessary columns (Comparison, Mean_A, Mean_B, P_Value).\n",
    "\n",
    "def prepare_and_calculate_change(df_ws, df_wg):\n",
    "    \"\"\"\n",
    "    PREPARES the dataframes, calculates the initial Mean_Change (first derivative),\n",
    "    and sets up the chronological X-axis positions.\n",
    "\n",
    "    Returns: df_combined (with X_Position and Mean_Change), ordered_comparisons list\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Ensure 'Inventory' column exists on the results DataFrames\n",
    "    if 'Inventory' not in df_ws.columns:\n",
    "        df_ws['Inventory'] = 'Words & Sentences (WS)'\n",
    "    if 'Inventory' not in df_wg.columns:\n",
    "        df_wg['Inventory'] = 'Words & Gestures (WG)'\n",
    "        \n",
    "    # 2. Prepare dataframes for calculation\n",
    "    for df in [df_ws, df_wg]:\n",
    "        df['Mean_A'] = pd.to_numeric(df['Mean_A'], errors='coerce')\n",
    "        df['Mean_B'] = pd.to_numeric(df['Mean_B'], errors='coerce')\n",
    "        df['P_Value'] = pd.to_numeric(df['P_Value'], errors='coerce')\n",
    "        # Calculate Change (First Derivative)\n",
    "        df['Mean_Change'] = df['Mean_B'] - df['Mean_A']\n",
    "    \n",
    "    # 3. Combine dataframes\n",
    "    df_combined = pd.concat([df_ws, df_wg], ignore_index=True)\n",
    "\n",
    "    # --- LOGIC FOR X-AXIS ORDERING AND PLOTTING ---\n",
    "    # 3a. Extract the starting age (e.g., 8 from '8m -> 9m') for numerical sorting\n",
    "    df_combined['Start_Age_Int'] = df_combined['Comparison'].apply(\n",
    "        lambda x: int(x.split('m')[0])\n",
    "    )\n",
    "\n",
    "    # 3b. Sort the unique comparison labels chronologically\n",
    "    sorted_comparisons_df = df_combined[['Comparison', 'Start_Age_Int']].drop_duplicates().sort_values(by='Start_Age_Int')\n",
    "    ordered_comparisons = sorted_comparisons_df['Comparison'].tolist()\n",
    "    \n",
    "    # 3c. Create a mapping from Comparison string to its numerical index (0, 1, 2, ...)\n",
    "    comparison_to_index = {comp: i for i, comp in enumerate(ordered_comparisons)}\n",
    "    \n",
    "    # 3d. Apply the mapping to create the explicit X-coordinate column\n",
    "    df_combined['X_Position'] = df_combined['Comparison'].map(comparison_to_index)\n",
    "    \n",
    "    return df_combined, ordered_comparisons\n",
    "\n",
    "def calculate_acceleration_data(df_combined):\n",
    "    \"\"\"\n",
    "    CALCULATES the Acceleration (second derivative) from the Mean_Change column.\n",
    "    \"\"\"\n",
    "    def calculate_acceleration(group):\n",
    "        # Acceleration is the difference between the current change and the previous change.\n",
    "        group['Acceleration'] = group['Mean_Change'].diff()\n",
    "        return group\n",
    "    \n",
    "    # Need to sort explicitly by age before calculating the difference, then group by Inventory\n",
    "    df_combined_sorted = df_combined.sort_values(by=['Inventory', 'Start_Age_Int'])\n",
    "    df_combined = df_combined_sorted.groupby('Inventory', sort=False).apply(calculate_acceleration).reset_index(drop=True)\n",
    "    \n",
    "    return df_combined.dropna(subset=['Acceleration']) # Acceleration only exists from the second transition onward\n",
    "\n",
    "def plot_monthly_change(df_combined, ordered_comparisons):\n",
    "    \"\"\"\n",
    "    Plots the monthly change in mean proportion (First Derivative).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # WS Data (Blue circles)\n",
    "    df_ws_plot = df_combined[df_combined['Inventory'].astype(str).str.contains('WS')]\n",
    "    plt.scatter(\n",
    "        df_ws_plot['X_Position'], \n",
    "        df_ws_plot['Mean_Change'], \n",
    "        color='blue', \n",
    "        label='Words & Sentences (WS) Change', \n",
    "        s=100, \n",
    "        alpha=0.7,\n",
    "        marker='o'\n",
    "    )\n",
    "    \n",
    "    # WG Data (Orange squares)\n",
    "    df_wg_plot = df_combined[df_combined['Inventory'].astype(str).str.contains('WG')]\n",
    "    plt.scatter(\n",
    "        df_wg_plot['X_Position'], \n",
    "        df_wg_plot['Mean_Change'], \n",
    "        color='orange', \n",
    "        label='Words & Gestures (WG) Change', \n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        marker='s' \n",
    "    )\n",
    "    \n",
    "    # Highlight significant decreases (Red stars)\n",
    "    sig_decreases = df_combined[\n",
    "        (df_combined['P_Value'] < 0.05) & \n",
    "        (df_combined['Mean_Change'] < 0)\n",
    "    ]\n",
    "    if not sig_decreases.empty:\n",
    "        plt.scatter(\n",
    "            sig_decreases['X_Position'], \n",
    "            sig_decreases['Mean_Change'],\n",
    "            color='red',\n",
    "            marker='*',\n",
    "            s=250, \n",
    "            label='Statistically Significant Decrease',\n",
    "            zorder=10 \n",
    "        )\n",
    "\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=1) \n",
    "    plt.title('Monthly Change in Mean Vocabulary Proportion', fontsize=14)\n",
    "    plt.ylabel('Change in Mean Proportion (Age B - Age A)', fontsize=12)\n",
    "    \n",
    "    # --- LEGEND FIX (Point 3) ---\n",
    "    # Placing the legend outside the top right of the plot area\n",
    "    plt.legend(title='Inventory', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    \n",
    "    # Set the x-ticks explicitly using the index (0, 1, 2...) and the sorted labels\n",
    "    plt.gca().set_xticks(range(len(ordered_comparisons)))\n",
    "    plt.gca().set_xticklabels(ordered_comparisons)\n",
    "    \n",
    "    # Rotate x-axis labels for readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_acceleration(df_accel, ordered_comparisons):\n",
    "    \"\"\"\n",
    "    Plots the monthly acceleration (Second Derivative) as a scatterplot (Point 2).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # WS Data (Blue circles)\n",
    "    df_ws_accel = df_accel[df_accel['Inventory'].astype(str).str.contains('WS')]\n",
    "    plt.scatter(\n",
    "        df_ws_accel['X_Position'], \n",
    "        df_ws_accel['Acceleration'], \n",
    "        color='blue', \n",
    "        label='WS Acceleration',\n",
    "        s=100,\n",
    "        marker='o'\n",
    "    )\n",
    "\n",
    "    # WG Data (Orange squares)\n",
    "    df_wg_accel = df_accel[df_accel['Inventory'].astype(str).str.contains('WG')]\n",
    "    plt.scatter(\n",
    "        df_wg_accel['X_Position'], \n",
    "        df_wg_accel['Acceleration'], \n",
    "        color='orange', \n",
    "        label='WG Acceleration',\n",
    "        s=100,\n",
    "        marker='s'\n",
    "    )\n",
    "\n",
    "    plt.axhline(0, color='red', linestyle='-', linewidth=1) \n",
    "    plt.title('Monthly Acceleration (Change in Growth Rate)', fontsize=14)\n",
    "    plt.xlabel('Age Transition (Comparison)', fontsize=12)\n",
    "    plt.ylabel('Acceleration (Change - Previous Change)', fontsize=12)\n",
    "    \n",
    "    # Placing the legend outside the top right of the plot area\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "\n",
    "    # Set the x-ticks explicitly. Note: the first comparison (e.g., 8m->9m) has no acceleration.\n",
    "    # We plot the acceleration data frame, which has the X_Position correctly mapped.\n",
    "    # However, for labels, we use the original ordered comparisons list.\n",
    "    plt.gca().set_xticks(range(len(ordered_comparisons)))\n",
    "    plt.gca().set_xticklabels(ordered_comparisons)\n",
    "    \n",
    "    # Rotate x-axis labels for readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXECUTION ---\n",
    "# The execution block is separated to show how you can run these in your notebook cells.\n",
    "\n",
    "# Cell 1: Data Preparation\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"   STEP 1: CALCULATING CHANGE (First Derivative)\")\n",
    "print(f\"{'='*40}\\n\")\n",
    "df_combined_change, ordered_comparisons = prepare_and_calculate_change(df_WS_results, df_WG_results)\n",
    "display(df_combined_change.head()) # Display combined structure\n",
    "\n",
    "# Cell 2: Plot Monthly Change\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"   STEP 2: PLOTTING MONTHLY CHANGE\")\n",
    "print(f\"{'='*40}\\n\")\n",
    "plot_monthly_change(df_combined_change, ordered_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Calculate Acceleration\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"   STEP 3: CALCULATING ACCELERATION (Second Derivative)\")\n",
    "print(f\"{'='*40}\\n\")\n",
    "df_combined_accel = calculate_acceleration_data(df_combined_change)\n",
    "display(df_combined_accel.head()) # Display acceleration structure\n",
    "\n",
    "# Cell 4: Plot Acceleration\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"   STEP 4: PLOTTING ACCELERATION\")\n",
    "print(f\"{'='*40}\\n\")\n",
    "plot_acceleration(df_combined_accel, ordered_comparisons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ASSUMPTION ---\n",
    "# This script assumes the original dataframe df_WS is loaded and available in the environment,\n",
    "# and it contains a 'category' column and age columns as strings ('27', '28', '29').\n",
    "\n",
    "def analyze_category_contribution(df_ws):\n",
    "    \"\"\"\n",
    "    Analyzes which word categories drive the extreme acceleration (27m->28m) \n",
    "    and deceleration (28m->29m) observed in the Words & Sentences inventory.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the critical age columns\n",
    "    age_A = '27'\n",
    "    age_B = '28'\n",
    "    age_C = '29'\n",
    "    \n",
    "    required_cols = ['category', age_A, age_B, age_C]\n",
    "    \n",
    "    # 1. Prepare and clean the data\n",
    "    df = df_ws[required_cols].copy()\n",
    "    \n",
    "    # Convert age columns to numeric, coercing errors to NaN\n",
    "    for col in [age_A, age_B, age_C]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "    # Drop rows where the category is missing or any of the key age data points are missing\n",
    "    df = df.dropna(subset=required_cols)\n",
    "\n",
    "    # 2. Calculate the mean proportion for each category at the three key ages\n",
    "    category_means = df.groupby('category')[[age_A, age_B, age_C]].mean().reset_index()\n",
    "\n",
    "    # 3. Calculate the change for the two critical phases\n",
    "    \n",
    "    # Phase 1: Acceleration (27m -> 28m)\n",
    "    category_means['Change_27_to_28'] = category_means[age_B] - category_means[age_A]\n",
    "    \n",
    "    # Phase 2: Deceleration/Dip (28m -> 29m)\n",
    "    category_means['Change_28_to_29'] = category_means[age_C] - category_means[age_B]\n",
    "    \n",
    "    # Calculate the Acceleration/Deceleration magnitude\n",
    "    # This is the difference between the two changes: (Change_B - Change_A)\n",
    "    # A large negative value here indicates the sharp deceleration/dip.\n",
    "    category_means['Acceleration_Diff'] = category_means['Change_28_to_29'] - category_means['Change_27_to_28']\n",
    "\n",
    "    # 4. Format and present results\n",
    "    \n",
    "    # Rename columns for clarity in output\n",
    "    category_means.rename(columns={\n",
    "        age_A: 'Mean_27m',\n",
    "        age_B: 'Mean_28m',\n",
    "        age_C: 'Mean_29m'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Select and format final columns\n",
    "    results_cols = [\n",
    "        'category',\n",
    "        'Mean_27m',\n",
    "        'Mean_28m',\n",
    "        'Mean_29m',\n",
    "        'Change_27_to_28',\n",
    "        'Change_28_to_29',\n",
    "        'Acceleration_Diff'\n",
    "    ]\n",
    "    results_df = category_means[results_cols]\n",
    "    \n",
    "    # Order by the most severe deceleration (most negative Acceleration_Diff)\n",
    "    results_df = results_df.sort_values(by='Acceleration_Diff', ascending=True)\n",
    "\n",
    "    # Apply formatting for display\n",
    "    float_cols = ['Mean_27m', 'Mean_28m', 'Mean_29m', 'Change_27_to_28', 'Change_28_to_29', 'Acceleration_Diff']\n",
    "    for col in float_cols:\n",
    "        results_df[col] = results_df[col].map('{:.4f}'.format)\n",
    "        \n",
    "    return results_df\n",
    "\n",
    "# --- EXECUTION ---\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(\"       ANALYZING CATEGORY CONTRIBUTION TO THE 28m PEAK AND DIP (WS Inventory)\")\n",
    "print(f\"{'='*90}\\n\")\n",
    "\n",
    "# NOTE: This execution assumes df_WS is available in your environment.\n",
    "category_results = analyze_category_contribution(df_WS)\n",
    "display(category_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WS['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSUMPTION: df_WS is the raw Words & Sentences DataFrame and is available.\n",
    "# This function replicates the category analysis to correctly identify the top \n",
    "# volatile categories internally, ensuring the plot uses the right labels.\n",
    "\n",
    "def plot_volatile_categories(df_ws, num_top_categories=3):\n",
    "    \"\"\"\n",
    "    Identifies the most volatile categories (largest negative Acceleration_Diff) \n",
    "    around the 28m mark and plots their mean proportion over all ages.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Re-run analysis to identify the most volatile categories\n",
    "    age_A, age_B, age_C = '27', '28', '29'\n",
    "    required_cols = ['category', age_A, age_B, age_C]\n",
    "    df = df_ws[required_cols].copy()\n",
    "    \n",
    "    for col in [age_A, age_B, age_C]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "    df = df.dropna(subset=required_cols)\n",
    "    category_means_snap = df.groupby('category')[[age_A, age_B, age_C]].mean().reset_index()\n",
    "\n",
    "    category_means_snap['Change_27_to_28'] = category_means_snap[age_B] - category_means_snap[age_A]\n",
    "    category_means_snap['Change_28_to_29'] = category_means_snap[age_C] - category_means_snap[age_B]\n",
    "    category_means_snap['Acceleration_Diff'] = category_means_snap['Change_28_to_29'] - category_means_snap['Change_27_to_28']\n",
    "\n",
    "    # Get the names of the top N most volatile categories (most negative diff)\n",
    "    volatile_categories = category_means_snap.sort_values(by='Acceleration_Diff', ascending=True)['category'].head(num_top_categories).tolist()\n",
    "    \n",
    "    print(\"Categories selected for plotting (most negative Acceleration_Diff):\")\n",
    "    for cat in volatile_categories:\n",
    "        print(f\" - {cat}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # 2. Prepare full time-series data\n",
    "    \n",
    "    # Get all numeric age columns (e.g., '8', '9', ..., '30')\n",
    "    potential_age_cols = df_ws.columns.difference(['item_id', 'item_definition', 'category']).tolist()\n",
    "    age_cols = sorted([col for col in potential_age_cols if str(col).isdigit()], key=int)\n",
    "    \n",
    "    # Filter original data to include only the volatile categories\n",
    "    df_filtered = df_ws[df_ws['category'].isin(volatile_categories)].copy()\n",
    "    \n",
    "    # Ensure age columns are numeric for calculation\n",
    "    df_filtered[age_cols] = df_filtered[age_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Calculate the mean proportion for the selected categories across all ages\n",
    "    plot_data = df_filtered.groupby('category')[age_cols].mean().T\n",
    "    plot_data.index = plot_data.index.astype(int) # Convert age index to integer for plotting\n",
    "\n",
    "    # 3. Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for category in volatile_categories:\n",
    "        plt.plot(\n",
    "            plot_data.index, \n",
    "            plot_data[category], \n",
    "            marker='o', \n",
    "            linestyle='-', \n",
    "            label=f'Category: {category.replace(\"_\", \" \").title()}',\n",
    "            alpha=0.7\n",
    "        )\n",
    "\n",
    "    # Highlight the 27m to 29m region with a shaded background\n",
    "    plt.axvspan(26.5, 29.5, color='red', alpha=0.1, label='Volatility Region (27m-29m)')\n",
    "    \n",
    "    plt.title('Mean Proportion Produced Over Time for Most Volatile Categories', fontsize=16)\n",
    "    plt.xlabel('Age (Months)', fontsize=12)\n",
    "    plt.ylabel('Mean Proportion of Items Produced', fontsize=12)\n",
    "    plt.xticks(plot_data.index)\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    \n",
    "    # Legend placement fix\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Category')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_volatile_categories(df_WS, num_top_categories=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_categories_means(df_ws):\n",
    "    \"\"\"\n",
    "    Plots the mean proportion over all ages for ALL categories as a scatterplot\n",
    "    with connecting lines to show the trajectory over time.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Identify all categories\n",
    "    all_categories = df_ws['category'].unique().tolist()\n",
    "    \n",
    "    print(\"Preparing time series data for all categories...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # 2. Prepare full time-series data\n",
    "    \n",
    "    # Get all numeric age columns (e.g., '8', '9', ..., '30')\n",
    "    potential_age_cols = df_ws.columns.difference(['item_id', 'item_definition', 'category']).tolist()\n",
    "    age_cols = sorted([col for col in potential_age_cols if str(col).isdigit()], key=int)\n",
    "    \n",
    "    # Filter original data to include only the relevant columns and ensure numeric\n",
    "    df_filtered = df_ws[df_ws['category'].isin(all_categories)].copy()\n",
    "    \n",
    "    # Ensure age columns are numeric for calculation\n",
    "    df_filtered[age_cols] = df_filtered[age_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Calculate the mean proportion for ALL categories across all ages\n",
    "    plot_data = df_filtered.groupby('category')[age_cols].mean().T\n",
    "    plot_data.index = plot_data.index.astype(int) # Convert age index to integer for plotting\n",
    "\n",
    "    # 3. Plotting\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Use plt.plot with solid line style\n",
    "    for category in all_categories:\n",
    "        plt.plot(\n",
    "            plot_data.index, \n",
    "            plot_data[category], \n",
    "            marker='o', \n",
    "            linestyle='-', # Lines re-added for clarity\n",
    "            label=f'Category: {category.replace(\"_\", \" \").title()}',\n",
    "            alpha=0.6,\n",
    "            markersize=5\n",
    "        )\n",
    "\n",
    "    # Highlight the 27m to 29m region with a shaded background\n",
    "    plt.axvspan(26.5, 29.5, color='red', alpha=0.1, label='Volatility Region (27m-29m)')\n",
    "    \n",
    "    plt.title('Mean Proportion Produced Over Time for ALL Categories (WS Inventory)', fontsize=16)\n",
    "    plt.xlabel('Age (Months)', fontsize=12)\n",
    "    plt.ylabel('Mean Proportion of Items Produced', fontsize=12)\n",
    "    plt.xticks(plot_data.index)\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    \n",
    "    # Legend placement fix\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Category', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_categories_means(df_WS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_item_volatility(df_ws, num_items=10):\n",
    "    \"\"\"\n",
    "    Analyzes which individual items drive the extreme acceleration (27m->28m) \n",
    "    and deceleration (28m->29m) observed in the Words & Sentences inventory.\n",
    "    \n",
    "    The analysis calculates the 'Acceleration_Diff' (Volatility) for each item,\n",
    "    where a large negative value indicates a strong spike at 28m followed by a crash at 29m.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the critical age columns for the analysis\n",
    "    age_A = '27'\n",
    "    age_B = '28'\n",
    "    age_C = '29'\n",
    "    \n",
    "    required_cols = ['item_definition', 'category', age_A, age_B, age_C]\n",
    "    \n",
    "    # 1. Prepare and clean the data\n",
    "    df = df_ws[required_cols].copy()\n",
    "    \n",
    "    # Convert age columns to numeric, coercing errors to NaN\n",
    "    for col in [age_A, age_B, age_C]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "    # Drop rows where any of the key age data points are missing\n",
    "    df = df.dropna(subset=[age_A, age_B, age_C])\n",
    "\n",
    "    # 2. Calculate volatility metrics for each item\n",
    "    \n",
    "    # Phase 1: Gain (27m -> 28m)\n",
    "    df['Change_27_to_28'] = df[age_B] - df[age_A]\n",
    "    \n",
    "    # Phase 2: Dip (28m -> 29m)\n",
    "    df['Change_28_to_29'] = df[age_C] - df[age_B]\n",
    "    \n",
    "    # Calculate the Acceleration/Deceleration magnitude (Volatility)\n",
    "    # A large negative value = strong spike (gain) followed by a strong dip (loss/crash)\n",
    "    df['Acceleration_Diff'] = df['Change_28_to_29'] - df['Change_27_to_28']\n",
    "\n",
    "    # 3. Format and present top results\n",
    "    \n",
    "    # Order by the most severe deceleration (most negative Acceleration_Diff)\n",
    "    results_df = df.sort_values(by='Acceleration_Diff', ascending=True)\n",
    "    \n",
    "    # Select the top N most volatile items\n",
    "    top_volatile_items = results_df.head(num_items)\n",
    "\n",
    "    # Select and format final columns\n",
    "    final_cols = [\n",
    "        'item_definition',\n",
    "        'category',\n",
    "        age_A,\n",
    "        age_B,\n",
    "        age_C,\n",
    "        'Change_27_to_28',\n",
    "        'Change_28_to_29',\n",
    "        'Acceleration_Diff'\n",
    "    ]\n",
    "    \n",
    "    final_df = top_volatile_items[final_cols].copy()\n",
    "    \n",
    "    # Apply formatting for display (Keep a copy before converting for plotting)\n",
    "    plot_df = final_df.copy()\n",
    "    \n",
    "    float_cols = [age_A, age_B, age_C, 'Change_27_to_28', 'Change_28_to_29', 'Acceleration_Diff']\n",
    "    for col in float_cols:\n",
    "        final_df[col] = final_df[col].map('{:.4f}'.format)\n",
    "        \n",
    "    # Return both the display-formatted table and the plot-ready dataframe\n",
    "    return final_df, plot_df # Returning two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*100}\")\n",
    "print(\"   ANALYZING THE TOP 10 INDIVIDUAL ITEMS DRIVING THE 28m PEAK AND DIP (WS Inventory)\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "item_results, plot_data_df = analyze_item_volatility(df_WS, num_items=10)\n",
    "display(item_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_item_volatility(plot_df):\n",
    "    \"\"\"\n",
    "    Creates a grouped bar chart to visualize the magnitude of the spike (27->28m) \n",
    "    versus the crash (28m->29m) for the top volatile items.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure columns are numeric for plotting\n",
    "    plot_df['Change_27_to_28'] = pd.to_numeric(plot_df['Change_27_to_28'], errors='coerce')\n",
    "    plot_df['Change_28_to_29'] = pd.to_numeric(plot_df['Change_28_to_29'], errors='coerce')\n",
    "    \n",
    "    # Prepare data for grouped bar chart\n",
    "    labels = plot_df['item_definition'] + ' (' + plot_df['category'] + ')'\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    # Bar for the Spike (27m -> 28m)\n",
    "    rects1 = ax.bar(x - width/2, plot_df['Change_27_to_28'], width, \n",
    "                    label='Gain (27m → 28m)', color='#3b82f6')\n",
    "    \n",
    "    # Bar for the Crash (28m -> 29m)\n",
    "    rects2 = ax.bar(x + width/2, plot_df['Change_28_to_29'], width, \n",
    "                    label='Loss/Crash (28m → 29m)', color='#ef4444')\n",
    "\n",
    "    # Customization\n",
    "    ax.set_ylabel('Change in Proportion Acquired', fontsize=12)\n",
    "    ax.set_xlabel('Item Definition and Category', fontsize=12)\n",
    "    ax.set_title('Top 10 Item Volatility: Spike vs. Crash at 28 Months', fontsize=16)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "    \n",
    "    # Add a zero line for reference\n",
    "    ax.axhline(0, color='gray', linewidth=0.8)\n",
    "    \n",
    "    ax.legend(loc='upper right')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_item_volatility(plot_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "erdos_ds_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
