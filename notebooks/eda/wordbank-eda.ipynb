{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WS = pd.read_csv('~/Desktop/LingPredict data/wordbank_data_WS_Produces_en_US.csv')\n",
    "df_WS.drop(columns=['downloaded'], inplace=True)\n",
    "display(df_WS.head())\n",
    "\n",
    "df_WG = pd.read_csv('~/Desktop/LingPredict data/wordbank_data_WG_Produces_en_US.csv')\n",
    "df_WG.drop(columns=['downloaded'], inplace=True)\n",
    "df_WG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_WS['item_definition'].unique()\n",
    "print(len(words))\n",
    "words = df_WG['item_definition'].unique()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_lemmas_WS = pd.read_csv('~/Desktop/LingPredict data/uni_lemmas_WS_en_US.csv')\n",
    "uni_lemmas_WG = pd.read_csv('~/Desktop/LingPredict data/uni_lemmas_WG_en_US.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uni_lemmas_WS.head())\n",
    "display(uni_lemmas_WG.head())\n",
    "\n",
    "print(uni_lemmas_WS.shape)\n",
    "uni_lemmas_WG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_reorder_lemma_data(df_main, df_lemma_lookup, inventory_name):\n",
    "    \"\"\"\n",
    "    Merges the 'uni_lemma' column from the lookup table into the main DataFrame\n",
    "    and reorders the columns so 'uni_lemma' is the third column (after item_id \n",
    "    and item_definition).\n",
    "\n",
    "    Args:\n",
    "        df_main (pd.DataFrame): The main DataFrame (e.g., df_WS or df_WG).\n",
    "        df_lemma_lookup (pd.DataFrame): The lemma mapping table (e.g., uni_lemmas_WS or uni_lemmas_WG).\n",
    "        inventory_name (str): The name of the inventory for print output (e.g., 'WS' or 'WG').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with the new column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform a Left Merge\n",
    "    # - 'left': df_WS (the original acquisition data)\n",
    "    # - 'right': uni_lemmas_WS (the table containing the uni_lemma to add)\n",
    "    # - 'on': 'item_definition' (the common key)\n",
    "    # - 'how': 'left' (ensures all rows from df_WS are kept, even if no match is found)\n",
    "    df_main = pd.merge(\n",
    "        df_main, \n",
    "        df_lemma_lookup, \n",
    "        on='item_definition', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # 3. REORDER COLUMNS\n",
    "    # Define the desired core columns in order\n",
    "    core_cols = ['item_id', 'uni_lemma', 'item_definition']\n",
    "\n",
    "    # Filter core_cols to only include those present in the main DataFrame\n",
    "    present_core_cols = [col for col in core_cols if col in df_main.columns]\n",
    "    \n",
    "    # Get all columns that are NOT the core columns, maintaining their original order\n",
    "    original_cols = df_main.columns.tolist()\n",
    "    other_cols = [col for col in original_cols if col not in present_core_cols]\n",
    "\n",
    "    # Create the final desired column order\n",
    "    new_column_order = present_core_cols + other_cols\n",
    "\n",
    "    # Apply the new column order\n",
    "    df_main = df_main[new_column_order]\n",
    "\n",
    "    print(f\"--- {inventory_name} Dataframe Updated ---\")\n",
    "    print(f\"df_{inventory_name} has been updated with the 'uni_lemma' column and reordered.\")\n",
    "    print(\"Displaying the first few rows of the core columns:\")\n",
    "    print(df_main[present_core_cols].head())\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    return df_main\n",
    "\n",
    "# =========================================================================\n",
    "# EXECUTION: Applying the operation to both WS and WG DataFrames\n",
    "# NOTE: This assumes df_WS, uni_lemmas_WS, df_WG, and uni_lemmas_WG are available.\n",
    "# =========================================================================\n",
    "\n",
    "# 1. Apply to WS Data\n",
    "df_WS = merge_and_reorder_lemma_data(df_WS, uni_lemmas_WS, 'WS')\n",
    "\n",
    "# 2. Apply to WG Data (The new request)\n",
    "df_WG = merge_and_reorder_lemma_data(df_WG, uni_lemmas_WG, 'WG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_WS.head())\n",
    "display(df_WG.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_lemmas_WG[uni_lemmas_WG['uni_lemma'] == 'in']\n",
    "uni_lemmas_WG[uni_lemmas_WG['uni_lemma'] == 'inside']\n",
    "uni_lemmas_WS[uni_lemmas_WS['uni_lemma'] == 'in']\n",
    "uni_lemmas_WS[uni_lemmas_WS['uni_lemma'] == 'inside']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all words in WG are in WS. Check which ones are missing.\n",
    "print(df_WS.shape, df_WG.shape)\n",
    "print(df_WG['item_definition'].isin(df_WS['item_definition']).all())\n",
    "mask = df_WG['item_definition'].isin(df_WS['item_definition'])\n",
    "missing = df_WG[~mask]\n",
    "print(f\"Number of WG words not in WS: {(len(missing))}\")\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually, it's just that inside and in were combined into one item \"inside/in\" in WS.\n",
    "df_WS.iloc[622:623]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the \"inside/in\" row into two rows, one for \"inside\" and one for \"in\".\n",
    "\n",
    "# --- 1. Isolate the row and create copies ---\n",
    "\n",
    "# Isolate the target row\n",
    "original_row = df_WS[df_WS['item_definition'] == 'inside/in'].copy()\n",
    "\n",
    "# Create the new 'in' row (deepcopy is a safe practice)\n",
    "new_row_in = original_row.copy()\n",
    "new_row_in['item_definition'] = 'in'\n",
    "\n",
    "# Create the new 'inside' row\n",
    "new_row_inside = original_row.copy()\n",
    "new_row_inside['item_definition'] = 'inside'\n",
    "new_row_inside['uni_lemma'] = 'inside'\n",
    "\n",
    "\n",
    "# --- 2. Remove the original row from the main DataFrame ---\n",
    "\n",
    "# Filter out the 'inside/in' row.\n",
    "df_WS = df_WS[df_WS['item_definition'] != 'inside/in'].copy()\n",
    "\n",
    "\n",
    "# --- 3. Concatenate the filtered DF with the two new rows ---\n",
    "\n",
    "# Combine the filtered data with the two new rows\n",
    "df_WS = pd.concat(\n",
    "    [df_WS, new_row_in, new_row_inside],\n",
    "    ignore_index=True  # Optional: resets the index\n",
    ")\n",
    "\n",
    "print(\"Updated DataFrame (New 'in' and 'inside' rows added):\")\n",
    "display(df_WS[df_WS['item_definition'].isin(['in', 'inside'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all words in WG should be in WS\n",
    "print(df_WG['uni_lemma'].isin(df_WS['uni_lemma']).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which words in WS are not in WG?\n",
    "df_WS[~df_WS['item_definition'].isin(df_WG['item_definition'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes:\n",
    "    \n",
    "# 1) Across the board, the data for 28 months seems unusally high. For basically every word, the max proportion\n",
    "# occurs at 28 months, and even sometimes decreases at 29 and 30 months. Maybe drop the 28 column?\n",
    "# Sara mentioned that there might be a deveelopmental explanation for this.\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# 2) Find article explaining 28-month anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "baa_baa_WG = df_WG.iloc[0,:]\n",
    "EXCLUDE_COLS = ['item_id', 'uni_lemma', 'item_definition', 'category']\n",
    "age_cols = (baa_baa_WG.index).difference(EXCLUDE_COLS)\n",
    "#age_cols = baa_baa_WG.columns.difference(EXCLUDE_COLS)\n",
    "baa_baa_WG_proportions = baa_baa_WG.loc[age_cols]\n",
    "\n",
    "# 3. Create a DataFrame suitable for plotting with seaborn\n",
    "baa_baa_WG_df = pd.DataFrame({\n",
    "    # Age is the index label, which we convert to integer for plotting\n",
    "    'Age': baa_baa_WG_proportions.index.astype(int),\n",
    "    # Proportion is the value associated with each age\n",
    "    'Proportion Acquired': baa_baa_WG_proportions.values\n",
    "})\n",
    "display(baa_baa_WG_df)\n",
    "\n",
    "baa_baa_WS = df_WS.iloc[0,:]\n",
    "age_cols = (baa_baa_WS.index).difference(EXCLUDE_COLS)\n",
    "#age_cols = baa_baa_WS.columns.difference(EXCLUDE_COLS)\n",
    "baa_baa_WS_proportions = baa_baa_WS.loc[age_cols]\n",
    "\n",
    "# 3. Create a DataFrame suitable for plotting with seaborn\n",
    "baa_baa_WS_df = pd.DataFrame({\n",
    "    # Age is the index label, which we convert to integer for plotting\n",
    "    'Age': baa_baa_WS_proportions.index.astype(int),\n",
    "    # Proportion is the value associated with each age\n",
    "    'Proportion Acquired': baa_baa_WS_proportions.values\n",
    "})\n",
    "display(baa_baa_WS_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot WG Data (Orange Dots)\n",
    "plt.scatter(\n",
    "    baa_baa_WG_df['Age'],\n",
    "    baa_baa_WG_df['Proportion Acquired'],\n",
    "    color='orange',\n",
    "    s=80,\n",
    "    label='WG Inventory (8-18 mos)'\n",
    ")\n",
    "\n",
    "# Plot WS Data (Blue Dots)\n",
    "plt.scatter(\n",
    "    baa_baa_WS_df['Age'],\n",
    "    baa_baa_WS_df['Proportion Acquired'],\n",
    "    color='blue',\n",
    "    s=80,\n",
    "    label='WS Inventory (16-30 mos)'\n",
    ")\n",
    "\n",
    "# --- 4. Customizing the Plot ---\n",
    "plt.title('Acquisition Trajectory for \"baa baa\" Across Two Inventories')\n",
    "plt.xlabel('Child Age (Months)')\n",
    "plt.ylabel('Proportion of Children Acquired')\n",
    "plt.ylim(0, 1.05)\n",
    "# Set x-ticks to appear every 2 months from 8 to 30\n",
    "plt.xticks(np.arange(8, 31, 2))\n",
    "plt.legend(title='Data Source')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "baa_baa_WG_df['Inventory'] = 'WG'\n",
    "baa_baa_WS_df['Inventory'] = 'WS'\n",
    "baa_baa_df = pd.concat([baa_baa_WG_df, baa_baa_WS_df], ignore_index=True)\n",
    "display(baa_baa_df.head())\n",
    "baa_baa_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid_3param(age, L, k, x0):\n",
    "#     \"\"\"\n",
    "#     L: Maximum value (asymptote).\n",
    "#     k: Growth rate (steepness).\n",
    "#     x0: Inflection point (Median Age of Acquisition estimate).\n",
    "#     \"\"\"\n",
    "#     return L / (1 + np.exp(-k * (age - x0)))\n",
    "\n",
    "# # --- 3. Extract Data for Fitting ---\n",
    "# X = baa_baa_df['Age'].values  # Independent variable (Age)\n",
    "# Y = baa_baa_df['Proportion Acquired'].values # Dependent variable (Proportion)\n",
    "\n",
    "# # --- 4. Perform the Curve Fit ---\n",
    "# # p0 provides initial \"guesses\" for the parameters (L, k, x0).\n",
    "# popt, pcov = curve_fit(sigmoid_3param, X, Y, p0=[1.0, 0.5, 22])\n",
    "\n",
    "# # Extract the optimal fitted parameters\n",
    "# L_fit, k_fit, x0_fit = popt\n",
    "\n",
    "# # --- 5. Print Results ---\n",
    "# print(\"Fitted Parameters for Acquisition Trajectory:\")\n",
    "# print(\"-\" * 40)\n",
    "# print(f\"  Maximum Proportion (L): {L_fit:.4f}\")\n",
    "# print(f\"  Growth Rate (k): {k_fit:.4f}\")\n",
    "# print(f\"  Model-based Median AoA (x0): {x0_fit:.2f} months\")\n",
    "\n",
    "# # --- 6. Plot the Fitted Curve vs. Raw Data ---\n",
    "# X_fit = np.linspace(X.min(), X.max(), 100)\n",
    "# preds = sigmoid_3param(X_fit, L_fit, k_fit, x0_fit)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # --- Filter the Combined Data ---\n",
    "# df_wg = baa_baa_df[baa_baa_df['Inventory'] == 'WG']\n",
    "# df_ws = baa_baa_df[baa_baa_df['Inventory'] == 'WS']\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # 1. Raw Data Points: WG (Orange)\n",
    "# plt.scatter(\n",
    "#     df_wg['Age'],\n",
    "#     df_wg['Proportion Acquired'],\n",
    "#     label='WG Inventory Data (8-18 mos)',\n",
    "#     color='orange',\n",
    "#     s=80,\n",
    "#     edgecolors='black'\n",
    "# )\n",
    "\n",
    "# # 2. Raw Data Points: WS (Blue)\n",
    "# plt.scatter(\n",
    "#     df_ws['Age'],\n",
    "#     df_ws['Proportion Acquired'],\n",
    "#     label='WS Inventory Data (16-30 mos)',\n",
    "#     color='blue',\n",
    "#     s=80,\n",
    "#     edgecolors='black'\n",
    "# )\n",
    "\n",
    "# # Fitted Curve\n",
    "# plt.plot(X_fit, preds, label='Fitted Logistic Curve', color='red', linestyle='-', linewidth=2)\n",
    "\n",
    "# # Highlight the estimated AoA\n",
    "# plt.axvline(x=x0_fit, color='green', linestyle='--', label=f'Median AoA ({x0_fit:.2f} mo)')\n",
    "# plt.axhline(y=L_fit / 2, color='green', linestyle='--')\n",
    "\n",
    "# # Compare to 50% acquisition line\n",
    "# plt.axhline(y=0.5, color='darkred', linestyle=':', label='50% Acquisition Threshold', linewidth=1.5)\n",
    "\n",
    "# plt.title('Logistic Model Fit for Word Acquisition Trajectory')\n",
    "# plt.xlabel('Child Age (Months)')\n",
    "# plt.ylabel('Proportion of Children Acquired')\n",
    "# plt.ylim(0, 1.05)\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a 2-parameter sigmoid, fixing L=1, instead\n",
    "def sigmoid(age, k, x0):\n",
    "    \"\"\"\n",
    "    k: Growth rate.\n",
    "    x0: Inflection point / Median AoA.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-k * (age - x0)))\n",
    "\n",
    "# --- 3. Extract Data for Fitting ---\n",
    "X = baa_baa_df['Age'].values  # Independent variable (Age)\n",
    "Y = baa_baa_df['Proportion Acquired'].values # Dependent variable (Proportion)\n",
    "\n",
    "# --- 4. Perform the Curve Fit ---\n",
    "# p0 provides initial \"guesses\" for the parameters (L, k, x0).\n",
    "popt, pcov = curve_fit(sigmoid, X, Y, p0=[0.5, 22])\n",
    "\n",
    "# Extract the optimal fitted parameters\n",
    "k_fit, x0_fit = popt\n",
    "\n",
    "# --- 5. Print Results ---\n",
    "print(\"Fitted Parameters for Acquisition Trajectory:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  Growth Rate (k): {k_fit:.4f}\")\n",
    "print(f\"  Model-based Median AoA (x0): {x0_fit:.2f} months\")\n",
    "\n",
    "# --- 6. Plot the Fitted Curve vs. Raw Data ---\n",
    "X_fit = np.linspace(X.min(), X.max(), 100)\n",
    "preds = sigmoid(X_fit, k_fit, x0_fit)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# --- Filter the Combined Data ---\n",
    "df_wg = baa_baa_df[baa_baa_df['Inventory'] == 'WG']\n",
    "df_ws = baa_baa_df[baa_baa_df['Inventory'] == 'WS']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 1. Raw Data Points: WG (Orange)\n",
    "plt.scatter(\n",
    "    df_wg['Age'],\n",
    "    df_wg['Proportion Acquired'],\n",
    "    label='WG Inventory Data (8-18 mos)',\n",
    "    color='orange',\n",
    "    s=80,\n",
    "    edgecolors='black'\n",
    ")\n",
    "\n",
    "# 2. Raw Data Points: WS (Blue)\n",
    "plt.scatter(\n",
    "    df_ws['Age'],\n",
    "    df_ws['Proportion Acquired'],\n",
    "    label='WS Inventory Data (16-30 mos)',\n",
    "    color='blue',\n",
    "    s=80,\n",
    "    edgecolors='black'\n",
    ")\n",
    "\n",
    "# Fitted Curve\n",
    "plt.plot(X_fit, preds, label='Fitted Logistic Curve', color='red', linestyle='-', linewidth=2)\n",
    "\n",
    "# Highlight the estimated AoA\n",
    "plt.axvline(x=x0_fit, color='green', linestyle='--', label=f'Median AoA ({x0_fit:.2f} mo)')\n",
    "#plt.axhline(y=L_fit / 2, color='green', linestyle='--')\n",
    "\n",
    "# Compare to 50% acquisition line\n",
    "plt.axhline(y=0.5, color='darkred', linestyle=':', label='50% Acquisition Threshold', linewidth=1.5)\n",
    "\n",
    "plt.title('Logistic Model Fit for Word Acquisition Trajectory')\n",
    "plt.xlabel('Child Age (Months)')\n",
    "plt.ylabel('Proportion of Children Acquired')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(baa_baa_df)\n",
    "x0_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_WS_test_row = df_WS[df_WS['item_definition'] == 'baa baa']\n",
    "df_WS_test_row = df_WS[df_WS['item_definition'] == 'ant']\n",
    "item_def = df_WS_test_row['item_definition'].item()\n",
    "df_WG_test_row = df_WG[df_WG['item_definition'] == item_def]\n",
    "\n",
    "display(df_WS_test_row)\n",
    "display(df_WG_test_row)\n",
    "\n",
    "df_WS_test_row.columns.difference(['item_id', 'item_definition', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_WS_test_row)\n",
    "print(df_WG_test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def row_to_df_for_fit(df_row):\n",
    "#     \"\"\"\n",
    "#     Transforms a single wide-format DataFrame row into a clean long-format \n",
    "#     DataFrame (Age, Proportion) for logistic regression fitting.\n",
    "    \n",
    "#     Args:\n",
    "#         df_row (pd.DataFrame): A DataFrame containing exactly one row \n",
    "#                                of acquisition data\n",
    "#     \"\"\"\n",
    "#     # 1. Correctly identify data columns by excluding metadata columns\n",
    "#     EXCLUDE_COLS = ['item_id', 'item_definition', 'category']\n",
    "#     age_cols = df_row.columns.difference(EXCLUDE_COLS)\n",
    "    \n",
    "#     # 2. Correctly slice the DataFrame to get only the data values (Columns specified directly)\n",
    "#     # This result is still a 1-row DataFrame.\n",
    "#     proportions_wide = df_row[age_cols].copy()\n",
    "    \n",
    "#     # 3. Use pd.melt() on the single row to easily create the long format\n",
    "#     row_df = pd.melt(\n",
    "#         proportions_wide,\n",
    "#         ignore_index=False, # Important to keep the original index during melt\n",
    "#         value_vars=age_cols,\n",
    "#         var_name='Age',\n",
    "#         value_name='Proportion Acquired'\n",
    "#     )\n",
    "    \n",
    "#     # 4. Final cleaning and type conversion\n",
    "#     row_df = row_df.dropna(subset=['Proportion Acquired'])\n",
    "#     row_df['Age'] = row_df['Age'].astype(int)\n",
    "#     row_df = row_df.sort_values(by='Age')\n",
    "    \n",
    "#     return row_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_WS_df = row_to_df_for_fit(df_WS_test_row)\n",
    "# row_WG_df = row_to_df_for_fit(df_WG_test_row)\n",
    "# display(row_WS_df)\n",
    "# row_WG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_WS_df['Inventory'] = 'WS'\n",
    "# row_WG_df['Inventory'] = 'WG'\n",
    "# row_df_combined = pd.concat([row_WG_df, row_WS_df], ignore_index=True)\n",
    "# display(row_df_combined.head())\n",
    "# row_df_combined.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_sigmoid_params(row_combined):\n",
    "#     \"\"\"\n",
    "#     Fits the sigmoid curve to a single row and returns the parameters (k, x0).\n",
    "#     \"\"\"\n",
    "#     X = row_combined['Age'].values  # Independent variable (Age)\n",
    "#     Y = row_combined['Proportion Acquired'].values\n",
    "#     p0 = [0.5, 22] # Initial guesses (k, x0)\n",
    "\n",
    "#     try:\n",
    "#         # --- 4. Perform the Curve Fit ---\n",
    "#         # p0 provides initial \"guesses\" for the parameters (L, k, x0).\n",
    "#         popt, pcov = curve_fit(sigmoid, X, Y, p0=[0.5, 22])\n",
    "        \n",
    "#         # Return all three fitted parameters\n",
    "#         return pd.Series(popt, index=['k_fit', 'x0_fit'])\n",
    "        \n",
    "#     except RuntimeError:\n",
    "#         # If the fit fails, return a row of NaN values\n",
    "#         print(f\"Warning: Curve fit failed for row/word. Returning NaN.\")\n",
    "#         return pd.Series([np.nan, np.nan], index=['k_fit', 'x0_fit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_sigmoid_params(row_df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combined_logistic_regression(row_WS):\n",
    "#     '''\n",
    "#     Given a single WS row, find the corresponding WG row (if it exists),\n",
    "#     combine the data, and fit a logistic regression to the combined data.\n",
    "#     '''\n",
    "#     # Find corresponding WG row, if it exists\n",
    "#     item_def = df_WS_test_row['item_definition'].item()\n",
    "#     df_WG_test_row = df_WG[df_WG['item_definition'] == item_def]\n",
    "    \n",
    "#     row_WS_df = row_to_df_for_fit(df_WS_test_row)\n",
    "#     row_WG_df = row_to_df_for_fit(df_WG_test_row)\n",
    "#     row_df_combined = pd.concat([row_WG_df, row_WS_df], ignore_index=True)\n",
    "#     return calculate_sigmoid_params(row_df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_curve_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_curve_fits[['Growth Rate', 'Median AoA']] = df_WS.apply(calculate_sigmoid_params, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Helper Functions (Reused from previous steps) ---\n",
    "\n",
    "def row_to_df_for_fit(row_data):\n",
    "    \"\"\"\n",
    "    Transforms a single wide-format row into a clean long-format DataFrame.\n",
    "    \"\"\"\n",
    "    if isinstance(row_data, pd.Series):\n",
    "        df_row = row_data.to_frame().T\n",
    "    else:\n",
    "        df_row = row_data\n",
    "\n",
    "    EXCLUDE_COLS = ['item_id', 'uni_lemma' 'item_definition', 'category']\n",
    "    age_cols = df_row.columns.difference(EXCLUDE_COLS)\n",
    "    \n",
    "    proportions_wide = df_row[age_cols]\n",
    "    \n",
    "    row_df = pd.melt(\n",
    "        proportions_wide,\n",
    "        value_vars=age_cols,\n",
    "        var_name='Age',\n",
    "        value_name='Proportion Acquired'\n",
    "    )\n",
    "    \n",
    "    row_df = row_df.dropna(subset=['Proportion Acquired'])\n",
    "    row_df['Age'] = row_df['Age'].astype(int)\n",
    "    row_df = row_df.sort_values(by='Age')\n",
    "    \n",
    "    return row_df.reset_index(drop=True)\n",
    "\n",
    "def calculate_sigmoid_params(df_combined):\n",
    "    \"\"\"\n",
    "    Fits the sigmoid curve to the combined long-format data. \n",
    "    \"\"\"\n",
    "    X = df_combined['Age'].values\n",
    "    Y = df_combined['Proportion Acquired'].values\n",
    "    p0 = [0.5, X.mean() if X.size > 0 else 20] \n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(sigmoid, X, Y, p0=p0, maxfev=5000)\n",
    "        return pd.Series(\n",
    "            {'Growth Rate': popt[0], 'Median AoA': popt[1]}\n",
    "        )\n",
    "    except RuntimeError:\n",
    "        return pd.Series({'Growth Rate': np.nan, 'Median AoA': np.nan})\n",
    "\n",
    "# --- 3. The New Plotting Function (Refactored to use an ax object) ---\n",
    "\n",
    "def plot_acquisition_curve(ax, word, df_data, k_fit, x0_fit):\n",
    "    \"\"\"\n",
    "    Generates a scatter plot of the raw data, overlays the fitted logistic curve,\n",
    "    and adds median AoA and 50% lines onto the provided Axes (ax) object.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define colors for scatter plot (Requirement 1 & 2)\n",
    "    palette = {'WS': 'blue', 'WG': 'orange'}\n",
    "    sns.scatterplot(\n",
    "        data=df_data,\n",
    "        x='Age',\n",
    "        y='Proportion Acquired',\n",
    "        hue='Inventory',\n",
    "        palette=palette,\n",
    "        s=40, # Smaller points for better visibility in a grid\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        zorder=3,\n",
    "        ax=ax # Pass the axis object to seaborn\n",
    "    )\n",
    "\n",
    "    # --- Generate and Plot Fitted Curve (Requirement 3) ---\n",
    "    x_range = np.linspace(df_data['Age'].min() - 5, df_data['Age'].max() + 5, 100)\n",
    "    y_fitted = sigmoid(x_range, k_fit, x0_fit)\n",
    "    \n",
    "    ax.plot(\n",
    "        x_range, \n",
    "        y_fitted, \n",
    "        color='green', \n",
    "        linewidth=1.5, \n",
    "        label=f'Fitted Curve (k={k_fit:.2f})'\n",
    "    )\n",
    "\n",
    "    # --- Plot Vertical Median AoA Line (Requirement 4) ---\n",
    "    ax.axvline(\n",
    "        x=x0_fit,\n",
    "        color='green',\n",
    "        linestyle='--',\n",
    "        linewidth=1,\n",
    "        label=f'Median AoA ({x0_fit:.1f} mos)',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # --- Plot Horizontal 50% Acquisition Line (Requirement 5) ---\n",
    "    ax.axhline(\n",
    "        y=0.5, \n",
    "        color='red', \n",
    "        linestyle='--', \n",
    "        linewidth=1, \n",
    "        label='50% Threshold',\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    # --- Customization ---\n",
    "    ax.set_title(f'{word}', fontsize=10)\n",
    "    ax.set_xlabel('Age (Months)', fontsize=8)\n",
    "    ax.set_ylabel('Prop. Acquired', fontsize=8)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.set_xlim(df_data['Age'].min() - 2, df_data['Age'].max() + 2)\n",
    "    ax.grid(axis='both', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    # Remove the legend from each subplot to keep the grid clean\n",
    "    if ax.get_legend() is not None:\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "# Create the fast lookup dictionary for df_WG\n",
    "wg_dict = df_WG.set_index('item_definition').T.to_dict('series')\n",
    "\n",
    "# --- 5. EXECUTION & PLOTTING LOOP (Updated for Grid Layout) ---\n",
    "\n",
    "# Step A: Compute the Fits (refactored to return plot data explicitly)\n",
    "def combined_logistic_regression(ws_row, wg_dict):\n",
    "    item_def = ws_row['item_definition']\n",
    "    row_WS_long = row_to_df_for_fit(ws_row)\n",
    "    \n",
    "    if item_def in wg_dict:\n",
    "        wg_row_series = wg_dict[item_def]\n",
    "        row_WG_long = row_to_df_for_fit(wg_row_series)\n",
    "        row_WG_long['Inventory'] = 'WG' # Tag the data source\n",
    "        row_WS_long['Inventory'] = 'WS' # Tag WS data here too\n",
    "        row_df_combined = pd.concat([row_WG_long, row_WS_long], ignore_index=True)\n",
    "    else:\n",
    "        # If no WG match, tag the WS data\n",
    "        row_WS_long['Inventory'] = 'WS' \n",
    "        row_df_combined = row_WS_long\n",
    "    \n",
    "    # Fit the curve\n",
    "    fit_params = calculate_sigmoid_params(row_df_combined)\n",
    "    \n",
    "    # Add the plotting data to the Series being returned by .apply()\n",
    "    fit_params['__plot_data__'] = row_df_combined\n",
    "    \n",
    "    return fit_params\n",
    "\n",
    "# Run the fit and store results (results now includes all three keys)\n",
    "results = df_WS.apply(combined_logistic_regression, axis=1, wg_dict=wg_dict)\n",
    "\n",
    "# Initialize df_curve_fits and assign columns from the 'results' DataFrame\n",
    "df_curve_fits = df_WS[['uni_lemma']].copy()\n",
    "df_curve_fits = df_WS[['item_definition']].copy()\n",
    "df_curve_fits['Growth Rate'] = results['Growth Rate']\n",
    "df_curve_fits['Median AoA'] = results['Median AoA']\n",
    "\n",
    "# Assign the plot data directly from the collected 'results' Series\n",
    "df_curve_fits['__plot_data__'] = results['__plot_data__']\n",
    "\n",
    "print(\"--- Generated Plots (Displayed in a 6-Column Grid) ---\")\n",
    "\n",
    "# Step B: Setup Grid and Plot\n",
    "valid_fits = df_curve_fits[~pd.isna(df_curve_fits['Growth Rate'])]\n",
    "num_plots = len(valid_fits)\n",
    "COLS = 6 # Your specified number of columns\n",
    "ROWS = math.ceil(num_plots / COLS)\n",
    "\n",
    "# Set the overall figure size (adjust as needed for readability)\n",
    "fig, axes = plt.subplots(ROWS, COLS, figsize=(COLS * 3.5, ROWS * 3))\n",
    "\n",
    "# Flatten the axes array for simplified, reliable indexing\n",
    "if not isinstance(axes, np.ndarray):\n",
    "    # Handles the case where ROWS=1 and COLS=1 (axes is a single object)\n",
    "    axes = np.array([axes])\n",
    "else:\n",
    "    # Handles (1,N), (N,1), and (N,M) grids by flattening them to 1D\n",
    "    axes = axes.ravel() \n",
    "\n",
    "plot_index = 0\n",
    "for index, row in valid_fits.iterrows():\n",
    "    word = row['item_definition']\n",
    "    k_fit = row['Growth Rate']\n",
    "    x0_fit = row['Median AoA']\n",
    "    df_plot_data = row['__plot_data__']\n",
    "    \n",
    "    # Use the simple 1D index to access the correct subplot\n",
    "    ax = axes[plot_index] \n",
    "    \n",
    "    # Plot the curve using the current axis\n",
    "    plot_acquisition_curve(ax, word, df_plot_data, k_fit, x0_fit)\n",
    "    \n",
    "    plot_index += 1\n",
    "\n",
    "# Hide any unused subplots\n",
    "for i in range(plot_index, ROWS * COLS):\n",
    "    # Use the simple 1D index to hide axes\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Add a title for the entire figure and adjust layout\n",
    "fig.suptitle('Combined Acquisition Curve Fits', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust rect to make space for suptitle\n",
    "plt.show()\n",
    "\n",
    "if len(df_curve_fits) != len(valid_fits):\n",
    "    print(f\"\\nSkipped {len(df_curve_fits) - len(valid_fits)} items due to failed curve fit (NaN parameters).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WS.shape\n",
    "df_WS.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curve_fits[['uni_lemma', 'item_definition', 'Growth Rate', 'Median AoA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NOTE ---\n",
    "# This script assumes that df_WS, df_WG, and df_curve_fits have been successfully created \n",
    "# and are available in the current environment.\n",
    "\n",
    "# 1. Define the metadata/exclusion columns\n",
    "METADATA_COLS = ['item_id', 'item_definition', 'category']\n",
    "FIT_RESULT_COLS = ['item_definition', 'Growth Rate', 'Median AoA']\n",
    "\n",
    "# 2. Select the required columns and set 'item_definition' as the index for joining\n",
    "\n",
    "# Fit Results (Base DataFrame): Start with fit results and set index\n",
    "df_fit_summary = df_curve_fits[FIT_RESULT_COLS].copy()\n",
    "df_fit_summary = df_fit_summary.set_index('item_definition')\n",
    "\n",
    "# --- WS Age Data Processing ---\n",
    "AGE_COLS_WS = df_WS.columns.difference(METADATA_COLS).tolist()\n",
    "df_age_data_WS = df_WS[['item_definition'] + AGE_COLS_WS].set_index('item_definition')\n",
    "# Add suffix to uniquely identify WS age data\n",
    "df_age_data_WS.columns = [f'{col}_WS' if col in AGE_COLS_WS else col for col in df_age_data_WS.columns]\n",
    "\n",
    "# --- WG Age Data Processing ---\n",
    "AGE_COLS_WG = df_WG.columns.difference(METADATA_COLS).tolist()\n",
    "df_age_data_WG = df_WG[['item_definition'] + AGE_COLS_WG].set_index('item_definition')\n",
    "# Add suffix to uniquely identify WG age data\n",
    "df_age_data_WG.columns = [f'{col}_WG' if col in AGE_COLS_WG else col for col in df_age_data_WG.columns]\n",
    "\n",
    "\n",
    "# 3. Join the DataFrames horizontally using the 'item_definition' index.\n",
    "# The age columns are now unique (e.g., '16_WS', '16_WG'), preventing overlap issues.\n",
    "df_final_report = df_fit_summary.join(df_age_data_WS, how='left')\n",
    "df_final_report = df_final_report.join(df_age_data_WG, how='left')\n",
    "\n",
    "# Reset the index to make item_definition a regular column and put it first\n",
    "df_final_report = df_final_report.reset_index()\n",
    "\n",
    "# 4. Final display and shape check (including column reordering for clean output)\n",
    "\n",
    "# Collect all new age columns (now uniquely named)\n",
    "ws_suffix_cols = [f'{col}_WS' for col in AGE_COLS_WS]\n",
    "wg_suffix_cols = [f'{col}_WG' for col in AGE_COLS_WG]\n",
    "all_age_cols = sorted(list(set(ws_suffix_cols + wg_suffix_cols)), key=lambda x: int(x.split('_')[0]))\n",
    "\n",
    "FINAL_COL_ORDER = ['item_definition', 'Growth Rate', 'Median AoA'] + all_age_cols\n",
    "df_final_report = df_final_report[FINAL_COL_ORDER]\n",
    "\n",
    "\n",
    "print(\"--- Final Combined Report (Fit Results + WG/WS Age Proportions) ---\")\n",
    "df_final_report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's redo the analysis dropping the outlier 28-month data point\n",
    "df_WS_dropped = df_WS.drop(columns=['28'])\n",
    "print(df_WS_dropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Helper Functions (Reused from previous steps) ---\n",
    "\n",
    "def row_to_df_for_fit(row_data):\n",
    "    \"\"\"\n",
    "    Transforms a single wide-format row into a clean long-format DataFrame.\n",
    "    \"\"\"\n",
    "    if isinstance(row_data, pd.Series):\n",
    "        df_row = row_data.to_frame().T\n",
    "    else:\n",
    "        df_row = row_data\n",
    "\n",
    "    EXCLUDE_COLS = ['item_id', 'item_definition', 'category']\n",
    "    age_cols = df_row.columns.difference(EXCLUDE_COLS)\n",
    "    \n",
    "    proportions_wide = df_row[age_cols]\n",
    "    \n",
    "    row_df = pd.melt(\n",
    "        proportions_wide,\n",
    "        value_vars=age_cols,\n",
    "        var_name='Age',\n",
    "        value_name='Proportion Acquired'\n",
    "    )\n",
    "    \n",
    "    row_df = row_df.dropna(subset=['Proportion Acquired'])\n",
    "    row_df['Age'] = row_df['Age'].astype(int)\n",
    "    row_df = row_df.sort_values(by='Age')\n",
    "    \n",
    "    return row_df.reset_index(drop=True)\n",
    "\n",
    "def calculate_sigmoid_params(df_combined):\n",
    "    \"\"\"\n",
    "    Fits the sigmoid curve to the combined long-format data. \n",
    "    \"\"\"\n",
    "    X = df_combined['Age'].values\n",
    "    Y = df_combined['Proportion Acquired'].values\n",
    "    p0 = [0.5, X.mean() if X.size > 0 else 20] \n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(sigmoid, X, Y, p0=p0, maxfev=5000)\n",
    "        return pd.Series(\n",
    "            {'Growth Rate': popt[0], 'Median AoA': popt[1]}\n",
    "        )\n",
    "    except RuntimeError:\n",
    "        return pd.Series({'Growth Rate': np.nan, 'Median AoA': np.nan})\n",
    "\n",
    "# --- 3. The New Plotting Function (Refactored to use an ax object) ---\n",
    "\n",
    "def plot_acquisition_curve(ax, word, df_data, k_fit, x0_fit):\n",
    "    \"\"\"\n",
    "    Generates a scatter plot of the raw data, overlays the fitted logistic curve,\n",
    "    and adds median AoA and 50% lines onto the provided Axes (ax) object.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define colors for scatter plot (Requirement 1 & 2)\n",
    "    palette = {'WS': 'blue', 'WG': 'orange'}\n",
    "    sns.scatterplot(\n",
    "        data=df_data,\n",
    "        x='Age',\n",
    "        y='Proportion Acquired',\n",
    "        hue='Inventory',\n",
    "        palette=palette,\n",
    "        s=40, # Smaller points for better visibility in a grid\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        zorder=3,\n",
    "        ax=ax # Pass the axis object to seaborn\n",
    "    )\n",
    "\n",
    "    # --- Generate and Plot Fitted Curve (Requirement 3) ---\n",
    "    x_range = np.linspace(df_data['Age'].min() - 5, df_data['Age'].max() + 5, 100)\n",
    "    y_fitted = sigmoid(x_range, k_fit, x0_fit)\n",
    "    \n",
    "    ax.plot(\n",
    "        x_range, \n",
    "        y_fitted, \n",
    "        color='green', \n",
    "        linewidth=1.5, \n",
    "        label=f'Fitted Curve (k={k_fit:.2f})'\n",
    "    )\n",
    "\n",
    "    # --- Plot Vertical Median AoA Line (Requirement 4) ---\n",
    "    ax.axvline(\n",
    "        x=x0_fit,\n",
    "        color='green',\n",
    "        linestyle='--',\n",
    "        linewidth=1,\n",
    "        label=f'Median AoA ({x0_fit:.1f} mos)',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # --- Plot Horizontal 50% Acquisition Line (Requirement 5) ---\n",
    "    ax.axhline(\n",
    "        y=0.5, \n",
    "        color='red', \n",
    "        linestyle='--', \n",
    "        linewidth=1, \n",
    "        label='50% Threshold',\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    # --- Customization ---\n",
    "    ax.set_title(f'{word}', fontsize=10)\n",
    "    ax.set_xlabel('Age (Months)', fontsize=8)\n",
    "    ax.set_ylabel('Prop. Acquired', fontsize=8)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.set_xlim(df_data['Age'].min() - 2, df_data['Age'].max() + 2)\n",
    "    ax.grid(axis='both', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    # Remove the legend from each subplot to keep the grid clean\n",
    "    if ax.get_legend() is not None:\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "# Create the fast lookup dictionary for df_WG\n",
    "wg_dict = df_WG.set_index('item_definition').T.to_dict('series')\n",
    "\n",
    "# --- 5. EXECUTION & PLOTTING LOOP (Updated for Grid Layout) ---\n",
    "\n",
    "# Step A: Compute the Fits (refactored to return plot data explicitly)\n",
    "def combined_logistic_regression(ws_row, wg_dict):\n",
    "    item_def = ws_row['item_definition']\n",
    "    row_WS_long = row_to_df_for_fit(ws_row)\n",
    "    \n",
    "    if item_def in wg_dict:\n",
    "        wg_row_series = wg_dict[item_def]\n",
    "        row_WG_long = row_to_df_for_fit(wg_row_series)\n",
    "        row_WG_long['Inventory'] = 'WG' # Tag the data source\n",
    "        row_WS_long['Inventory'] = 'WS' # Tag WS data here too\n",
    "        row_df_combined = pd.concat([row_WG_long, row_WS_long], ignore_index=True)\n",
    "    else:\n",
    "        # If no WG match, tag the WS data\n",
    "        row_WS_long['Inventory'] = 'WS' \n",
    "        row_df_combined = row_WS_long\n",
    "    \n",
    "    # Fit the curve\n",
    "    fit_params = calculate_sigmoid_params(row_df_combined)\n",
    "    \n",
    "    # Add the plotting data to the Series being returned by .apply()\n",
    "    fit_params['__plot_data__'] = row_df_combined\n",
    "    \n",
    "    return fit_params\n",
    "\n",
    "# Run the fit and store results (results now includes all three keys)\n",
    "results = df_WS_dropped.apply(combined_logistic_regression, axis=1, wg_dict=wg_dict)\n",
    "\n",
    "# Initialize df_curve_fits_dropped and assign columns from the 'results' DataFrame\n",
    "df_curve_fits_dropped = df_WS_dropped[['item_definition']].copy()\n",
    "df_curve_fits_dropped['Growth Rate'] = results['Growth Rate']\n",
    "df_curve_fits_dropped['Median AoA'] = results['Median AoA']\n",
    "\n",
    "# Assign the plot data directly from the collected 'results' Series\n",
    "df_curve_fits_dropped['__plot_data__'] = results['__plot_data__']\n",
    "\n",
    "print(\"--- Generated Plots (Displayed in a 6-Column Grid) ---\")\n",
    "\n",
    "# Step B: Setup Grid and Plot\n",
    "valid_fits = df_curve_fits_dropped[~pd.isna(df_curve_fits_dropped['Growth Rate'])]\n",
    "num_plots = len(valid_fits)\n",
    "COLS = 6 # Your specified number of columns\n",
    "ROWS = math.ceil(num_plots / COLS)\n",
    "\n",
    "# Set the overall figure size (adjust as needed for readability)\n",
    "fig, axes = plt.subplots(ROWS, COLS, figsize=(COLS * 3.5, ROWS * 3))\n",
    "\n",
    "# Flatten the axes array for simplified, reliable indexing\n",
    "if not isinstance(axes, np.ndarray):\n",
    "    # Handles the case where ROWS=1 and COLS=1 (axes is a single object)\n",
    "    axes = np.array([axes])\n",
    "else:\n",
    "    # Handles (1,N), (N,1), and (N,M) grids by flattening them to 1D\n",
    "    axes = axes.ravel() \n",
    "\n",
    "plot_index = 0\n",
    "for index, row in valid_fits.iterrows():\n",
    "    word = row['item_definition']\n",
    "    k_fit = row['Growth Rate']\n",
    "    x0_fit = row['Median AoA']\n",
    "    df_plot_data = row['__plot_data__']\n",
    "    \n",
    "    # Use the simple 1D index to access the correct subplot\n",
    "    ax = axes[plot_index] \n",
    "    \n",
    "    # Plot the curve using the current axis\n",
    "    plot_acquisition_curve(ax, word, df_plot_data, k_fit, x0_fit)\n",
    "    \n",
    "    plot_index += 1\n",
    "\n",
    "# Hide any unused subplots\n",
    "for i in range(plot_index, ROWS * COLS):\n",
    "    # Use the simple 1D index to hide axes\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Add a title for the entire figure and adjust layout\n",
    "fig.suptitle('Combined Acquisition Curve Fits', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust rect to make space for suptitle\n",
    "plt.show()\n",
    "\n",
    "if len(df_curve_fits_dropped) != len(valid_fits):\n",
    "    print(f\"\\nSkipped {len(df_curve_fits_dropped) - len(valid_fits)} items due to failed curve fit (NaN parameters).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NOTE ---\n",
    "# This script assumes that df_WS, df_WG, and df_curve_fits have been successfully created \n",
    "# and are available in the current environment.\n",
    "\n",
    "# 1. Define the metadata/exclusion columns\n",
    "METADATA_COLS = ['item_id', 'item_definition', 'category']\n",
    "FIT_RESULT_COLS = ['item_definition', 'Growth Rate', 'Median AoA']\n",
    "\n",
    "# 2. Select the required columns and set 'item_definition' as the index for joining\n",
    "\n",
    "# Fit Results (Base DataFrame): Start with fit results and set index\n",
    "df_fit_summary = df_curve_fits_dropped[FIT_RESULT_COLS].copy()\n",
    "df_fit_summary = df_fit_summary.set_index('item_definition')\n",
    "\n",
    "# --- WS Age Data Processing ---\n",
    "AGE_COLS_WS = df_WS_dropped.columns.difference(METADATA_COLS).tolist()\n",
    "df_age_data_WS = df_WS_dropped[['item_definition'] + AGE_COLS_WS].set_index('item_definition')\n",
    "# Add suffix to uniquely identify WS age data\n",
    "df_age_data_WS.columns = [f'{col}_WS' if col in AGE_COLS_WS else col for col in df_age_data_WS.columns]\n",
    "\n",
    "# --- WG Age Data Processing ---\n",
    "AGE_COLS_WG = df_WG.columns.difference(METADATA_COLS).tolist()\n",
    "df_age_data_WG = df_WG[['item_definition'] + AGE_COLS_WG].set_index('item_definition')\n",
    "# Add suffix to uniquely identify WG age data\n",
    "df_age_data_WG.columns = [f'{col}_WG' if col in AGE_COLS_WG else col for col in df_age_data_WG.columns]\n",
    "\n",
    "\n",
    "# 3. Join the DataFrames horizontally using the 'item_definition' index.\n",
    "# The age columns are now unique (e.g., '16_WS', '16_WG'), preventing overlap issues.\n",
    "df_final_report_dropped = df_fit_summary.join(df_age_data_WS, how='left')\n",
    "df_final_report_dropped = df_final_report_dropped.join(df_age_data_WG, how='left')\n",
    "\n",
    "# Reset the index to make item_definition a regular column and put it first\n",
    "df_final_report_dropped = df_final_report_dropped.reset_index()\n",
    "\n",
    "# 4. Final display and shape check (including column reordering for clean output)\n",
    "\n",
    "# Collect all new age columns (now uniquely named)\n",
    "ws_suffix_cols = [f'{col}_WS' for col in AGE_COLS_WS]\n",
    "wg_suffix_cols = [f'{col}_WG' for col in AGE_COLS_WG]\n",
    "all_age_cols = sorted(list(set(ws_suffix_cols + wg_suffix_cols)), key=lambda x: int(x.split('_')[0]))\n",
    "\n",
    "FINAL_COL_ORDER = ['item_definition', 'Growth Rate', 'Median AoA'] + all_age_cols\n",
    "df_final_report_dropped = df_final_report_dropped[FINAL_COL_ORDER]\n",
    "\n",
    "\n",
    "print(\"--- Final Combined Report (Fit Results + WG/WS Age Proportions) ---\")\n",
    "df_final_report_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = df_curve_fits[['item_definition']].copy()\n",
    "df_compare[['Growth Rate Full', 'Median AoA Full']] = df_curve_fits[['Growth Rate', 'Median AoA']]\n",
    "df_compare[['Growth Rate Dropped', 'Median AoA Dropped']] = df_curve_fits_dropped[['Growth Rate', 'Median AoA']]\n",
    "df_compare['Delta Median AoA'] =  df_compare['Median AoA Full'] - df_compare['Median AoA Dropped']\n",
    "\n",
    "display(df_compare.head(10))\n",
    "print(df_compare['Delta Median AoA'].describe())\n",
    "df_compare['Delta Median AoA'].abs().argmax()\n",
    "print(df_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare.iloc[102,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare.sort_values(\n",
    "        by='Delta Median AoA', \n",
    "        key=lambda x: x.abs(), \n",
    "        ascending=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curve_fits_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_export = df_curve_fits_dropped[['item_definition', 'Growth Rate', 'Median AoA']]\n",
    "df_for_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'item_definition': 'token',\n",
    "    'Growth Rate': 'growth_rate',  # Check for typos or extra spaces here\n",
    "    'Median AoA': 'median_aoa'   # Check for typos or extra spaces here\n",
    "}\n",
    "df_for_export = df_for_export.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_export['l1'] = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_for_export.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_export.to_csv('~/Desktop/wordbank_en_logistc_fits.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_export.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_for_export.sort_values(by='median_aoa', ascending=True).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(uni_lemmas_WG[uni_lemmas_WG['item_definition'] == 'in'])\n",
    "display(uni_lemmas_WG[uni_lemmas_WG['item_definition'] == 'inside'])\n",
    "\n",
    "display(uni_lemmas_WS[uni_lemmas_WS['item_definition'] == 'in'])\n",
    "display(uni_lemmas_WS[uni_lemmas_WS['item_definition'] == 'inside'])\n",
    "display(uni_lemmas_WS[uni_lemmas_WS['item_definition'] == 'inside/in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = pd.read_csv('/Users/samschiavone/github/fall-2025-developmental-norms-and-language-acquisition/language_translation_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(translations[translations['uni_lemma'] == 'no'])\n",
    "display(translations[translations['uni_lemma'] == 'yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(uni_lemmas_WG[uni_lemmas_WG['uni_lemma'] == 'no'])\n",
    "display(uni_lemmas_WS[uni_lemmas_WS['uni_lemma'] == 'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
