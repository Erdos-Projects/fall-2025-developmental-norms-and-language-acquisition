{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WS = pd.read_csv('~/Desktop/LingPredict data/wordbank_data_WS_Produces_es_MX.csv')\n",
    "df_WS.drop(columns=['downloaded'], inplace=True)\n",
    "display(df_WS.head())\n",
    "print(df_WS.shape)\n",
    "\n",
    "df_WG = pd.read_csv('~/Desktop/LingPredict data/wordbank_data_WG_Produces_es_MX.csv')\n",
    "df_WG.drop(columns=['downloaded'], inplace=True)\n",
    "display(df_WG.head())\n",
    "df_WG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all item definitions lowercase for consistency\n",
    "df_WS['item_definition'] = df_WS['item_definition'].str.lower()\n",
    "df_WG['item_definition'] = df_WG['item_definition'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all words in WG are in WS. Check which ones are missing.\n",
    "print(df_WS.shape, df_WG.shape)\n",
    "print(df_WG['item_definition'].isin(df_WS['item_definition']).all())\n",
    "mask = df_WG['item_definition'].isin(df_WS['item_definition'])\n",
    "missing = df_WG[~mask]\n",
    "print(f\"Number of WG words not in WS: {(len(missing))}\")\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_WS[df_WS['item_definition'].str.contains('ver', na=False)])\n",
    "display(df_WS[df_WS['item_definition'].str.startswith('te', na=False)])\n",
    "display(df_WS[df_WS['item_definition'].str.contains('quÃ©', na=False)])\n",
    "display(df_WS[df_WS['item_definition'].str.contains('mano', na=False)])\n",
    "display(df_WS[df_WS['item_definition'].str.contains('cochera', na=False)])\n",
    "display(df_WS[df_WS['item_definition'].str.contains('bolsa', na=False)])\n",
    "display(df_WS[df_WS['item_definition'].str.contains('uno', na=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a 2-parameter sigmoid, fixing L=1, instead\n",
    "def sigmoid(age, k, x0):\n",
    "    \"\"\"\n",
    "    k: Growth rate.\n",
    "    x0: Inflection point / Median AoA.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-k * (age - x0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Helper Functions (Reused from previous steps) ---\n",
    "\n",
    "def row_to_df_for_fit(row_data):\n",
    "    \"\"\"\n",
    "    Transforms a single wide-format row into a clean long-format DataFrame.\n",
    "    \"\"\"\n",
    "    if isinstance(row_data, pd.Series):\n",
    "        df_row = row_data.to_frame().T\n",
    "    else:\n",
    "        df_row = row_data\n",
    "\n",
    "    EXCLUDE_COLS = ['item_id', 'item_definition', 'category']\n",
    "    age_cols = df_row.columns.difference(EXCLUDE_COLS)\n",
    "    \n",
    "    proportions_wide = df_row[age_cols]\n",
    "    \n",
    "    row_df = pd.melt(\n",
    "        proportions_wide,\n",
    "        value_vars=age_cols,\n",
    "        var_name='Age',\n",
    "        value_name='Proportion Acquired'\n",
    "    )\n",
    "    \n",
    "    row_df = row_df.dropna(subset=['Proportion Acquired'])\n",
    "    row_df['Age'] = row_df['Age'].astype(int)\n",
    "    row_df = row_df.sort_values(by='Age')\n",
    "    \n",
    "    return row_df.reset_index(drop=True)\n",
    "\n",
    "def calculate_sigmoid_params(df_combined):\n",
    "    \"\"\"\n",
    "    Fits the sigmoid curve to the combined long-format data. \n",
    "    \"\"\"\n",
    "    X = df_combined['Age'].values\n",
    "    Y = df_combined['Proportion Acquired'].values\n",
    "    p0 = [0.5, X.mean() if X.size > 0 else 20] \n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(sigmoid, X, Y, p0=p0, maxfev=5000)\n",
    "        return pd.Series(\n",
    "            {'Growth Rate': popt[0], 'Median AoA': popt[1]}\n",
    "        )\n",
    "    except RuntimeError:\n",
    "        return pd.Series({'Growth Rate': np.nan, 'Median AoA': np.nan})\n",
    "\n",
    "# --- 3. The New Plotting Function (Refactored to use an ax object) ---\n",
    "\n",
    "def plot_acquisition_curve(ax, word, df_data, k_fit, x0_fit):\n",
    "    \"\"\"\n",
    "    Generates a scatter plot of the raw data, overlays the fitted logistic curve,\n",
    "    and adds median AoA and 50% lines onto the provided Axes (ax) object.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define colors for scatter plot (Requirement 1 & 2)\n",
    "    palette = {'WS': 'blue', 'WG': 'orange'}\n",
    "    sns.scatterplot(\n",
    "        data=df_data,\n",
    "        x='Age',\n",
    "        y='Proportion Acquired',\n",
    "        hue='Inventory',\n",
    "        palette=palette,\n",
    "        s=40, # Smaller points for better visibility in a grid\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        zorder=3,\n",
    "        ax=ax # Pass the axis object to seaborn\n",
    "    )\n",
    "\n",
    "    # --- Generate and Plot Fitted Curve (Requirement 3) ---\n",
    "    x_range = np.linspace(df_data['Age'].min() - 5, df_data['Age'].max() + 5, 100)\n",
    "    y_fitted = sigmoid(x_range, k_fit, x0_fit)\n",
    "    \n",
    "    ax.plot(\n",
    "        x_range, \n",
    "        y_fitted, \n",
    "        color='green', \n",
    "        linewidth=1.5, \n",
    "        label=f'Fitted Curve (k={k_fit:.2f})'\n",
    "    )\n",
    "\n",
    "    # --- Plot Vertical Median AoA Line (Requirement 4) ---\n",
    "    ax.axvline(\n",
    "        x=x0_fit,\n",
    "        color='green',\n",
    "        linestyle='--',\n",
    "        linewidth=1,\n",
    "        label=f'Median AoA ({x0_fit:.1f} mos)',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # --- Plot Horizontal 50% Acquisition Line (Requirement 5) ---\n",
    "    ax.axhline(\n",
    "        y=0.5, \n",
    "        color='red', \n",
    "        linestyle='--', \n",
    "        linewidth=1, \n",
    "        label='50% Threshold',\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    # --- Customization ---\n",
    "    ax.set_title(f'{word}', fontsize=10)\n",
    "    ax.set_xlabel('Age (Months)', fontsize=8)\n",
    "    ax.set_ylabel('Prop. Acquired', fontsize=8)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.set_xlim(df_data['Age'].min() - 2, df_data['Age'].max() + 2)\n",
    "    ax.grid(axis='both', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    # Remove the legend from each subplot to keep the grid clean\n",
    "    if ax.get_legend() is not None:\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "# Create the fast lookup dictionary for df_WG\n",
    "wg_dict = df_WG.set_index('item_definition').T.to_dict('series')\n",
    "\n",
    "# --- 5. EXECUTION & PLOTTING LOOP (Updated for Grid Layout) ---\n",
    "\n",
    "# Step A: Compute the Fits (refactored to return plot data explicitly)\n",
    "def combined_logistic_regression(ws_row, wg_dict):\n",
    "    item_def = ws_row['item_definition']\n",
    "    row_WS_long = row_to_df_for_fit(ws_row)\n",
    "    \n",
    "    if item_def in wg_dict:\n",
    "        wg_row_series = wg_dict[item_def]\n",
    "        row_WG_long = row_to_df_for_fit(wg_row_series)\n",
    "        row_WG_long['Inventory'] = 'WG' # Tag the data source\n",
    "        row_WS_long['Inventory'] = 'WS' # Tag WS data here too\n",
    "        row_df_combined = pd.concat([row_WG_long, row_WS_long], ignore_index=True)\n",
    "    else:\n",
    "        # If no WG match, tag the WS data\n",
    "        row_WS_long['Inventory'] = 'WS' \n",
    "        row_df_combined = row_WS_long\n",
    "    \n",
    "    # Fit the curve\n",
    "    fit_params = calculate_sigmoid_params(row_df_combined)\n",
    "    \n",
    "    # Add the plotting data to the Series being returned by .apply()\n",
    "    fit_params['__plot_data__'] = row_df_combined\n",
    "    \n",
    "    return fit_params\n",
    "\n",
    "# Run the fit and store results (results now includes all three keys)\n",
    "results = df_WS.apply(combined_logistic_regression, axis=1, wg_dict=wg_dict)\n",
    "\n",
    "# Initialize df_curve_fits and assign columns from the 'results' DataFrame\n",
    "df_curve_fits = df_WS[['item_definition']].copy()\n",
    "df_curve_fits['Growth Rate'] = results['Growth Rate']\n",
    "df_curve_fits['Median AoA'] = results['Median AoA']\n",
    "\n",
    "# Assign the plot data directly from the collected 'results' Series\n",
    "df_curve_fits['__plot_data__'] = results['__plot_data__']\n",
    "\n",
    "print(\"--- Generated Plots (Displayed in a 6-Column Grid) ---\")\n",
    "\n",
    "# Step B: Setup Grid and Plot\n",
    "valid_fits = df_curve_fits[~pd.isna(df_curve_fits['Growth Rate'])]\n",
    "num_plots = len(valid_fits)\n",
    "COLS = 6 # Your specified number of columns\n",
    "ROWS = math.ceil(num_plots / COLS)\n",
    "\n",
    "# Set the overall figure size (adjust as needed for readability)\n",
    "fig, axes = plt.subplots(ROWS, COLS, figsize=(COLS * 3.5, ROWS * 3))\n",
    "\n",
    "# Flatten the axes array for simplified, reliable indexing\n",
    "if not isinstance(axes, np.ndarray):\n",
    "    # Handles the case where ROWS=1 and COLS=1 (axes is a single object)\n",
    "    axes = np.array([axes])\n",
    "else:\n",
    "    # Handles (1,N), (N,1), and (N,M) grids by flattening them to 1D\n",
    "    axes = axes.ravel() \n",
    "\n",
    "plot_index = 0\n",
    "for index, row in valid_fits.iterrows():\n",
    "    word = row['item_definition']\n",
    "    k_fit = row['Growth Rate']\n",
    "    x0_fit = row['Median AoA']\n",
    "    df_plot_data = row['__plot_data__']\n",
    "    \n",
    "    # Use the simple 1D index to access the correct subplot\n",
    "    ax = axes[plot_index] \n",
    "    \n",
    "    # Plot the curve using the current axis\n",
    "    plot_acquisition_curve(ax, word, df_plot_data, k_fit, x0_fit)\n",
    "    \n",
    "    plot_index += 1\n",
    "\n",
    "# Hide any unused subplots\n",
    "for i in range(plot_index, ROWS * COLS):\n",
    "    # Use the simple 1D index to hide axes\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Add a title for the entire figure and adjust layout\n",
    "fig.suptitle('Combined Acquisition Curve Fits', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust rect to make space for suptitle\n",
    "plt.show()\n",
    "\n",
    "if len(df_curve_fits) != len(valid_fits):\n",
    "    print(f\"\\nSkipped {len(df_curve_fits) - len(valid_fits)} items due to failed curve fit (NaN parameters).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's redo the analysis dropping the outlier 30-month data point\n",
    "df_WS_dropped = df_WS.drop(columns=['30'])\n",
    "print(df_WS_dropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fast lookup dictionary for df_WG\n",
    "wg_dict = df_WG.set_index('item_definition').T.to_dict('series')\n",
    "\n",
    "# --- 5. EXECUTION & PLOTTING LOOP (Updated for Grid Layout) ---\n",
    "\n",
    "# Step A: Compute the Fits (refactored to return plot data explicitly)\n",
    "def combined_logistic_regression(ws_row, wg_dict):\n",
    "    item_def = ws_row['item_definition']\n",
    "    row_WS_long = row_to_df_for_fit(ws_row)\n",
    "    \n",
    "    if item_def in wg_dict:\n",
    "        wg_row_series = wg_dict[item_def]\n",
    "        row_WG_long = row_to_df_for_fit(wg_row_series)\n",
    "        row_WG_long['Inventory'] = 'WG' # Tag the data source\n",
    "        row_WS_long['Inventory'] = 'WS' # Tag WS data here too\n",
    "        row_df_combined = pd.concat([row_WG_long, row_WS_long], ignore_index=True)\n",
    "    else:\n",
    "        # If no WG match, tag the WS data\n",
    "        row_WS_long['Inventory'] = 'WS' \n",
    "        row_df_combined = row_WS_long\n",
    "    \n",
    "    # Fit the curve\n",
    "    fit_params = calculate_sigmoid_params(row_df_combined)\n",
    "    \n",
    "    # Add the plotting data to the Series being returned by .apply()\n",
    "    fit_params['__plot_data__'] = row_df_combined\n",
    "    \n",
    "    return fit_params\n",
    "\n",
    "# Run the fit and store results (results now includes all three keys)\n",
    "results = df_WS_dropped.apply(combined_logistic_regression, axis=1, wg_dict=wg_dict)\n",
    "\n",
    "# Initialize df_curve_fits_dropped and assign columns from the 'results' DataFrame\n",
    "df_curve_fits_dropped = df_WS_dropped[['item_definition']].copy()\n",
    "df_curve_fits_dropped['Growth Rate'] = results['Growth Rate']\n",
    "df_curve_fits_dropped['Median AoA'] = results['Median AoA']\n",
    "\n",
    "# Assign the plot data directly from the collected 'results' Series\n",
    "df_curve_fits_dropped['__plot_data__'] = results['__plot_data__']\n",
    "\n",
    "print(\"--- Generated Plots (Displayed in a 6-Column Grid) ---\")\n",
    "\n",
    "# Step B: Setup Grid and Plot\n",
    "valid_fits = df_curve_fits_dropped[~pd.isna(df_curve_fits_dropped['Growth Rate'])]\n",
    "num_plots = len(valid_fits)\n",
    "COLS = 6 # Your specified number of columns\n",
    "ROWS = math.ceil(num_plots / COLS)\n",
    "\n",
    "# Set the overall figure size (adjust as needed for readability)\n",
    "fig, axes = plt.subplots(ROWS, COLS, figsize=(COLS * 3.5, ROWS * 3))\n",
    "\n",
    "# Flatten the axes array for simplified, reliable indexing\n",
    "if not isinstance(axes, np.ndarray):\n",
    "    # Handles the case where ROWS=1 and COLS=1 (axes is a single object)\n",
    "    axes = np.array([axes])\n",
    "else:\n",
    "    # Handles (1,N), (N,1), and (N,M) grids by flattening them to 1D\n",
    "    axes = axes.ravel() \n",
    "\n",
    "plot_index = 0\n",
    "for index, row in valid_fits.iterrows():\n",
    "    word = row['item_definition']\n",
    "    k_fit = row['Growth Rate']\n",
    "    x0_fit = row['Median AoA']\n",
    "    df_plot_data = row['__plot_data__']\n",
    "    \n",
    "    # Use the simple 1D index to access the correct subplot\n",
    "    ax = axes[plot_index] \n",
    "    \n",
    "    # Plot the curve using the current axis\n",
    "    plot_acquisition_curve(ax, word, df_plot_data, k_fit, x0_fit)\n",
    "    \n",
    "    plot_index += 1\n",
    "\n",
    "# Hide any unused subplots\n",
    "for i in range(plot_index, ROWS * COLS):\n",
    "    # Use the simple 1D index to hide axes\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Add a title for the entire figure and adjust layout\n",
    "fig.suptitle('Combined Acquisition Curve Fits', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust rect to make space for suptitle\n",
    "plt.show()\n",
    "\n",
    "if len(df_curve_fits_dropped) != len(valid_fits):\n",
    "    print(f\"\\nSkipped {len(df_curve_fits_dropped) - len(valid_fits)} items due to failed curve fit (NaN parameters).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mamÃ¡ and papÃ¡ are missing from WG table\n",
    "# instead they are listed as mamÃ¡/mami and papÃ¡/papi\n",
    "# should probably check for other rows with / in the item_definition\n",
    "display(df_WG[df_WG['item_definition'] == 'papÃ¡'])\n",
    "display(df_WS[df_WS['item_definition'] == 'papÃ¡'])\n",
    "display(df_WG[df_WG['item_definition'] == 'papÃ¡/papi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "slashes_WG = df_WG[df_WG['item_definition'].str.contains('/', na=False)]\n",
    "display(slashes_WG.head())\n",
    "print(slashes_WG.shape)\n",
    "\n",
    "slashes_WS = df_WS[df_WS['item_definition'].str.contains('/', na=False)]\n",
    "display(slashes_WS.head())\n",
    "print(slashes_WS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_WS[df_WS['item_definition'].str.contains('mam', na=False)])\n",
    "display(df_WS[df_WS['item_definition'].str.contains('pap', na=False)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_lemmas_WS = pd.read_csv('~/Desktop/LingPredict data/uni_lemmas_WS_es_MX.csv')\n",
    "uni_lemmas_WG = pd.read_csv('~/Desktop/LingPredict data/uni_lemmas_WG_es_MX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(uni_lemmas_WS.head())\n",
    "display(uni_lemmas_WG.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(uni_lemmas_WG[uni_lemmas_WG['uni_lemma'] == 'no'])\n",
    "display(uni_lemmas_WS[uni_lemmas_WS['uni_lemma'] == 'no'])\n",
    "display(uni_lemmas_WS[uni_lemmas_WS['item_definition'] == 'no'])\n",
    "display(df_WS[df_WS['item_definition'] == 'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
